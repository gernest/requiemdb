{"requiem":"declare module  '@requiemdb/rq'{\n /**\n * AggregationTemporality defines how a metric aggregator reports aggregated\n * values. It describes how those values relate to the time interval over\n * which they are aggregated.\n *\n * @generated from protobuf enum opentelemetry.proto.metrics.v1.AggregationTemporality\n */\nexport  enum AggregationTemporality {\n    /**\n     * UNSPECIFIED is the default AggregationTemporality, it MUST not be used.\n     *\n     * @generated from protobuf enum value: AGGREGATION_TEMPORALITY_UNSPECIFIED = 0;\n     */\n    UNSPECIFIED = 0,\n    /**\n     * DELTA is an AggregationTemporality for a metric aggregator which reports\n     * changes since last report time. Successive metrics contain aggregation of\n     * values from continuous and non-overlapping intervals.\n     *\n     * The values for a DELTA metric are based only on the time interval\n     * associated with one measurement cycle. There is no dependency on\n     * previous measurements like is the case for CUMULATIVE metrics.\n     *\n     * For example, consider a system measuring the number of requests that\n     * it receives and reports the sum of these requests every second as a\n     * DELTA metric:\n     *\n     *   1. The system starts receiving at time=t_0.\n     *   2. A request is received, the system measures 1 request.\n     *   3. A request is received, the system measures 1 request.\n     *   4. A request is received, the system measures 1 request.\n     *   5. The 1 second collection cycle ends. A metric is exported for the\n     *      number of requests received over the interval of time t_0 to\n     *      t_0+1 with a value of 3.\n     *   6. A request is received, the system measures 1 request.\n     *   7. A request is received, the system measures 1 request.\n     *   8. The 1 second collection cycle ends. A metric is exported for the\n     *      number of requests received over the interval of time t_0+1 to\n     *      t_0+2 with a value of 2.\n     *\n     * @generated from protobuf enum value: AGGREGATION_TEMPORALITY_DELTA = 1;\n     */\n    DELTA = 1,\n    /**\n     * CUMULATIVE is an AggregationTemporality for a metric aggregator which\n     * reports changes since a fixed start time. This means that current values\n     * of a CUMULATIVE metric depend on all previous measurements since the\n     * start time. Because of this, the sender is required to retain this state\n     * in some form. If this state is lost or invalidated, the CUMULATIVE metric\n     * values MUST be reset and a new fixed start time following the last\n     * reported measurement time sent MUST be used.\n     *\n     * For example, consider a system measuring the number of requests that\n     * it receives and reports the sum of these requests every second as a\n     * CUMULATIVE metric:\n     *\n     *   1. The system starts receiving at time=t_0.\n     *   2. A request is received, the system measures 1 request.\n     *   3. A request is received, the system measures 1 request.\n     *   4. A request is received, the system measures 1 request.\n     *   5. The 1 second collection cycle ends. A metric is exported for the\n     *      number of requests received over the interval of time t_0 to\n     *      t_0+1 with a value of 3.\n     *   6. A request is received, the system measures 1 request.\n     *   7. A request is received, the system measures 1 request.\n     *   8. The 1 second collection cycle ends. A metric is exported for the\n     *      number of requests received over the interval of time t_0 to\n     *      t_0+2 with a value of 5.\n     *   9. The system experiences a fault and loses state.\n     *   10. The system recovers and resumes receiving at time=t_1.\n     *   11. A request is received, the system measures 1 request.\n     *   12. The 1 second collection cycle ends. A metric is exported for the\n     *      number of requests received over the interval of time t_1 to\n     *      t_0+1 with a value of 1.\n     *\n     * Note: Even though, when reporting changes since last report time, using\n     * CUMULATIVE is valid, it is not recommended. This may cause problems for\n     * systems that do not use start_time to determine when the aggregation\n     * value was reset (e.g. Prometheus).\n     *\n     * @generated from protobuf enum value: AGGREGATION_TEMPORALITY_CUMULATIVE = 2;\n     */\n    CUMULATIVE = 2\n}\n\nexport class AnyValue$Type extends MessageType\u003cAnyValue\u003e {\n    constructor();\n    create(value?: PartialMessage\u003cAnyValue\u003e): AnyValue;\n    internalBinaryRead(reader: IBinaryReader, length: number, options: BinaryReadOptions, target?: AnyValue): AnyValue;\n    internalBinaryWrite(message: AnyValue, writer: IBinaryWriter, options: BinaryWriteOptions): IBinaryWriter;\n}\n\n/**\n * AnyValue is used to represent any type of attribute value. AnyValue may contain a\n * primitive value such as a string or integer or it may contain an arbitrary nested\n * object containing arrays, key-value lists and primitives.\n *\n * @generated from protobuf message opentelemetry.proto.common.v1.AnyValue\n */\nexport  interface AnyValue {\n    /**\n     * @generated from protobuf oneof: value\n     */\n    value: {\n        oneofKind: \"stringValue\";\n        /**\n         * @generated from protobuf field: string string_value = 1;\n         */\n        stringValue: string;\n    } | {\n        oneofKind: \"boolValue\";\n        /**\n         * @generated from protobuf field: bool bool_value = 2;\n         */\n        boolValue: boolean;\n    } | {\n        oneofKind: \"intValue\";\n        /**\n         * @generated from protobuf field: int64 int_value = 3;\n         */\n        intValue: number;\n    } | {\n        oneofKind: \"doubleValue\";\n        /**\n         * @generated from protobuf field: double double_value = 4;\n         */\n        doubleValue: number;\n    } | {\n        oneofKind: \"arrayValue\";\n        /**\n         * @generated from protobuf field: opentelemetry.proto.common.v1.ArrayValue array_value = 5;\n         */\n        arrayValue: ArrayValue;\n    } | {\n        oneofKind: \"kvlistValue\";\n        /**\n         * @generated from protobuf field: opentelemetry.proto.common.v1.KeyValueList kvlist_value = 6;\n         */\n        kvlistValue: KeyValueList;\n    } | {\n        oneofKind: \"bytesValue\";\n        /**\n         * @generated from protobuf field: bytes bytes_value = 7;\n         */\n        bytesValue: Uint8Array;\n    } | {\n        oneofKind: undefined;\n    };\n}\n\n/**\n * @generated MessageType for protobuf message opentelemetry.proto.common.v1.AnyValue\n */\nexport  const AnyValue: AnyValue$Type;\n\nexport class ArrayValue$Type extends MessageType\u003cArrayValue\u003e {\n    constructor();\n    create(value?: PartialMessage\u003cArrayValue\u003e): ArrayValue;\n    internalBinaryRead(reader: IBinaryReader, length: number, options: BinaryReadOptions, target?: ArrayValue): ArrayValue;\n    internalBinaryWrite(message: ArrayValue, writer: IBinaryWriter, options: BinaryWriteOptions): IBinaryWriter;\n}\n\n/**\n * ArrayValue is a list of AnyValue messages. We need ArrayValue as a message\n * since oneof in AnyValue does not allow repeated fields.\n *\n * @generated from protobuf message opentelemetry.proto.common.v1.ArrayValue\n */\nexport  interface ArrayValue {\n    /**\n     * Array of values. The array may be empty (contain 0 elements).\n     *\n     * @generated from protobuf field: repeated opentelemetry.proto.common.v1.AnyValue values = 1;\n     */\n    values: AnyValue[];\n}\n\n/**\n * @generated MessageType for protobuf message opentelemetry.proto.common.v1.ArrayValue\n */\nexport  const ArrayValue: ArrayValue$Type;\n\n/**\n * Options for reading binary data.\n */\nexport interface BinaryReadOptions {\n    /**\n     * Shall unknown fields be read, ignored or raise an error?\n     *\n     * `true`: stores the unknown field on a symbol property of the\n     * message. This is the default behaviour.\n     *\n     * `false`: ignores the unknown field.\n     *\n     * `\"throw\"`: throws an error.\n     *\n     * `UnknownFieldReader`: Your own behaviour for unknown fields.\n     */\n    readUnknownField: boolean | 'throw' | UnknownFieldReader;\n    /**\n     * Allows to use a custom implementation to parse binary data.\n     */\n    readerFactory: (bytes: Uint8Array) =\u003e IBinaryReader;\n}\n\n/**\n * Options for writing binary data.\n */\nexport interface BinaryWriteOptions {\n    /**\n     * Shall unknown fields be written back on wire?\n     *\n     * `true`: unknown fields stored in a symbol property of the message\n     * are written back. This is the default behaviour.\n     *\n     * `false`: unknown fields are not written.\n     *\n     * `UnknownFieldWriter`: Your own behaviour for unknown fields.\n     */\n    writeUnknownFields: boolean | UnknownFieldWriter;\n    /**\n     * Allows to use a custom implementation to encode binary data.\n     */\n    writerFactory: () =\u003e IBinaryWriter;\n}\n\nexport  class Config {\n    base: Scan;\n    constructor(scope: Scan_SCOPE);\n    scan(): ScanData;\n    /**\n     * Limits the number of matched samples to process during scanning.\n     *\n     * @param num_samples maximum number of matched samples to process\n     * @returns\n     */\n    limit(num_samples: number): this;\n    /**\n     * Duration relative to current scanning time to start evaluation.\n     *   endTime = current_scan_time - offset\n     *\n     * @param duration\n     * @returns\n     */\n    offset(duration: Duration): this;\n    reverse(): this;\n    resourceSchema(schema: string): this;\n    scopeSchema(schema: string): this;\n    scopeName(name: string): this;\n    scopeVersion(version: string): this;\n    name(value: string): this;\n    traceId(value: string): this;\n    spanId(value: string): this;\n    parentSpanId(value: string): this;\n    logLevel(value: string): this;\n    resourceAttr(key: string, value: string): this;\n    scopeAttr(key: string, value: string): this;\n    attr(key: string, value: string): this;\n    private baseFilter;\n    private attrFilter;\n    filter(f: Scan_Filter): this;\n    /**\n     *\n     * @returns samples for the last 15 minutes\n     */\n    latest(): this;\n    today(): this;\n    thisWeek(): this;\n    thisYear(): this;\n    /**\n     *\n     * @param duration is ISO 8601 duration string\n     * @returns\n     */\n    ago(duration: string): this;\n    thisMonth(): this;\n    /**\n     * Sets timeRange field using native range Object. This is much faster\n     *  and efficient than serializing to/from protocol buffer.\n     *\n     * @param range is a native js.Range object\n     * @returns\n     */\n    protected setRange(range: any): this;\n}\n\nexport class Data$Type extends MessageType\u003cData\u003e {\n    constructor();\n}\n\n/**\n * @generated from protobuf message v1.Data\n */\nexport  interface Data {\n    /**\n     * @generated from protobuf oneof: data\n     */\n    data: {\n        oneofKind: \"metrics\";\n        /**\n         * @generated from protobuf field: opentelemetry.proto.metrics.v1.MetricsData metrics = 1;\n         */\n        metrics: MetricsData;\n    } | {\n        oneofKind: \"logs\";\n        /**\n         * @generated from protobuf field: opentelemetry.proto.logs.v1.LogsData logs = 2;\n         */\n        logs: LogsData;\n    } | {\n        oneofKind: \"trace\";\n        /**\n         * @generated from protobuf field: opentelemetry.proto.trace.v1.TracesData trace = 3;\n         */\n        trace: TracesData;\n    } | {\n        oneofKind: undefined;\n    };\n}\n\n/**\n * @generated MessageType for protobuf message v1.Data\n */\nexport  const Data: Data$Type;\n\n/**\n * DataPointFlags is defined as a protobuf 'uint32' type and is to be used as a\n * bit-field representing 32 distinct boolean flags.  Each flag defined in this\n * enum is a bit-mask.  To test the presence of a single flag in the flags of\n * a data point, for example, use an expression like:\n *\n *   (point.flags \u0026 DATA_POINT_FLAGS_NO_RECORDED_VALUE_MASK) == DATA_POINT_FLAGS_NO_RECORDED_VALUE_MASK\n *\n *\n * @generated from protobuf enum opentelemetry.proto.metrics.v1.DataPointFlags\n */\nexport  enum DataPointFlags {\n    /**\n     * The zero value for the enum. Should not be used for comparisons.\n     * Instead use bitwise \"and\" with the appropriate mask as shown above.\n     *\n     * @generated from protobuf enum value: DATA_POINT_FLAGS_DO_NOT_USE = 0;\n     */\n    DO_NOT_USE = 0,\n    /**\n     * This DataPoint is valid but has no recorded value.  This value\n     * SHOULD be used to reflect explicitly missing data in a series, as\n     * for an equivalent to the Prometheus \"staleness marker\".\n     *\n     * @generated from protobuf enum value: DATA_POINT_FLAGS_NO_RECORDED_VALUE_MASK = 1;\n     */\n    NO_RECORDED_VALUE_MASK = 1\n}\n\nexport class Duration$Type extends MessageType\u003cDuration\u003e {\n    constructor();\n    /**\n     * Encode `Duration` to JSON string like \"3.000001s\".\n     */\n    internalJsonWrite(message: Duration, options: JsonWriteOptions): JsonValue;\n    /**\n     * Decode `Duration` from JSON string like \"3.000001s\"\n     */\n    internalJsonRead(json: JsonValue, options: JsonReadOptions, target?: Duration): Duration;\n}\n\n/**\n * A Duration represents a signed, fixed-length span of time represented\n * as a count of seconds and fractions of seconds at nanosecond\n * resolution. It is independent of any calendar and concepts like \"day\"\n * or \"month\". It is related to Timestamp in that the difference between\n * two Timestamp values is a Duration and it can be added or subtracted\n * from a Timestamp. Range is approximately +-10,000 years.\n *\n * # Examples\n *\n * Example 1: Compute Duration from two Timestamps in pseudo code.\n *\n *     Timestamp start = ...;\n *     Timestamp end = ...;\n *     Duration duration = ...;\n *\n *     duration.seconds = end.seconds - start.seconds;\n *     duration.nanos = end.nanos - start.nanos;\n *\n *     if (duration.seconds \u003c 0 \u0026\u0026 duration.nanos \u003e 0) {\n *       duration.seconds += 1;\n *       duration.nanos -= 1000000000;\n *     } else if (duration.seconds \u003e 0 \u0026\u0026 duration.nanos \u003c 0) {\n *       duration.seconds -= 1;\n *       duration.nanos += 1000000000;\n *     }\n *\n * Example 2: Compute Timestamp from Timestamp + Duration in pseudo code.\n *\n *     Timestamp start = ...;\n *     Duration duration = ...;\n *     Timestamp end = ...;\n *\n *     end.seconds = start.seconds + duration.seconds;\n *     end.nanos = start.nanos + duration.nanos;\n *\n *     if (end.nanos \u003c 0) {\n *       end.seconds -= 1;\n *       end.nanos += 1000000000;\n *     } else if (end.nanos \u003e= 1000000000) {\n *       end.seconds += 1;\n *       end.nanos -= 1000000000;\n *     }\n *\n * Example 3: Compute Duration from datetime.timedelta in Python.\n *\n *     td = datetime.timedelta(days=3, minutes=10)\n *     duration = Duration()\n *     duration.FromTimedelta(td)\n *\n * # JSON Mapping\n *\n * In JSON format, the Duration type is encoded as a string rather than an\n * object, where the string ends in the suffix \"s\" (indicating seconds) and\n * is preceded by the number of seconds, with nanoseconds expressed as\n * fractional seconds. For example, 3 seconds with 0 nanoseconds should be\n * encoded in JSON format as \"3s\", while 3 seconds and 1 nanosecond should\n * be expressed in JSON format as \"3.000000001s\", and 3 seconds and 1\n * microsecond should be expressed in JSON format as \"3.000001s\".\n *\n *\n * @generated from protobuf message google.protobuf.Duration\n */\nexport  interface Duration {\n    /**\n     * Signed seconds of the span of time. Must be from -315,576,000,000\n     * to +315,576,000,000 inclusive. Note: these bounds are computed from:\n     * 60 sec/min * 60 min/hr * 24 hr/day * 365.25 days/year * 10000 years\n     *\n     * @generated from protobuf field: int64 seconds = 1;\n     */\n    seconds: number;\n    /**\n     * Signed fractions of a second at nanosecond resolution of the span\n     * of time. Durations less than one second are represented with a 0\n     * `seconds` field and a positive or negative `nanos` field. For durations\n     * of one second or more, a non-zero value for the `nanos` field must be\n     * of the same sign as the `seconds` field. Must be from -999,999,999\n     * to +999,999,999 inclusive.\n     *\n     * @generated from protobuf field: int32 nanos = 2;\n     */\n    nanos: number;\n}\n\n/**\n * @generated MessageType for protobuf message google.protobuf.Duration\n */\nexport  const Duration: Duration$Type;\n\n/**\n * Describes a protobuf enum for runtime reflection.\n *\n * The tuple consists of:\n *\n *\n * [0] the protobuf type name\n *\n * The type name follows the same rules as message type names.\n * See `MessageInfo` for details.\n *\n *\n * [1] the enum object generated by Typescript\n *\n * We generate standard Typescript enums for protobuf enums. They are compiled\n * to lookup objects that map from numerical value to name strings and vice\n * versa and can also contain alias names.\n *\n * See https://www.typescriptlang.org/docs/handbook/enums.html#reverse-mappings\n *\n * We use this lookup feature to when encoding / decoding JSON format. The\n * enum is guaranteed to have a value for 0. We generate an entry for 0 if\n * none was declared in .proto because we would need to support custom default\n * values if we didn't.\n *\n *\n * [2] the prefix shared by all original enum values (optional)\n *\n * If all values of a protobuf enum share a prefix, it is dropped in the\n * generated enum. For example, the protobuf enum `enum My { MY_FOO, MY_BAR }`\n * becomes the typescript enum `enum My { FOO, BAR }`.\n *\n * Because the JSON format requires the original value name, we store the\n * dropped prefix here, so that the JSON format implementation can restore\n * the original value names.\n */\nexport type EnumInfo = readonly [\n/**\n* The protobuf type name of the enum\n*/\nstring, \n/**\n* The enum object generated by Typescript\n*/\n    {\n    [key: number]: string;\n    [k: string]: number | string;\n}, \n/**\n* The prefix shared by all original enum values\n*/\nstring?];\n\nexport class Exemplar$Type extends MessageType\u003cExemplar\u003e {\n    constructor();\n    create(value?: PartialMessage\u003cExemplar\u003e): Exemplar;\n    internalBinaryRead(reader: IBinaryReader, length: number, options: BinaryReadOptions, target?: Exemplar): Exemplar;\n    internalBinaryWrite(message: Exemplar, writer: IBinaryWriter, options: BinaryWriteOptions): IBinaryWriter;\n}\n\n/**\n * A representation of an exemplar, which is a sample input measurement.\n * Exemplars also hold information about the environment when the measurement\n * was recorded, for example the span and trace ID of the active span when the\n * exemplar was recorded.\n *\n * @generated from protobuf message opentelemetry.proto.metrics.v1.Exemplar\n */\nexport  interface Exemplar {\n    /**\n     * The set of key/value pairs that were filtered out by the aggregator, but\n     * recorded alongside the original measurement. Only key/value pairs that were\n     * filtered out by the aggregator should be included\n     *\n     * @generated from protobuf field: repeated opentelemetry.proto.common.v1.KeyValue filtered_attributes = 7;\n     */\n    filteredAttributes: KeyValue[];\n    /**\n     * time_unix_nano is the exact time when this exemplar was recorded\n     *\n     * Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January\n     * 1970.\n     *\n     * @generated from protobuf field: fixed64 time_unix_nano = 2;\n     */\n    timeUnixNano: number;\n    /**\n     * @generated from protobuf oneof: value\n     */\n    value: {\n        oneofKind: \"asDouble\";\n        /**\n         * @generated from protobuf field: double as_double = 3;\n         */\n        asDouble: number;\n    } | {\n        oneofKind: \"asInt\";\n        /**\n         * @generated from protobuf field: sfixed64 as_int = 6;\n         */\n        asInt: number;\n    } | {\n        oneofKind: undefined;\n    };\n    /**\n     * (Optional) Span ID of the exemplar trace.\n     * span_id may be missing if the measurement is not recorded inside a trace\n     * or if the trace is not sampled.\n     *\n     * @generated from protobuf field: bytes span_id = 4;\n     */\n    spanId: Uint8Array;\n    /**\n     * (Optional) Trace ID of the exemplar trace.\n     * trace_id may be missing if the measurement is not recorded inside a trace\n     * or if the trace is not sampled.\n     *\n     * @generated from protobuf field: bytes trace_id = 5;\n     */\n    traceId: Uint8Array;\n}\n\n/**\n * @generated MessageType for protobuf message opentelemetry.proto.metrics.v1.Exemplar\n */\nexport  const Exemplar: Exemplar$Type;\n\nexport class ExponentialHistogram$Type extends MessageType\u003cExponentialHistogram\u003e {\n    constructor();\n    create(value?: PartialMessage\u003cExponentialHistogram\u003e): ExponentialHistogram;\n    internalBinaryRead(reader: IBinaryReader, length: number, options: BinaryReadOptions, target?: ExponentialHistogram): ExponentialHistogram;\n    internalBinaryWrite(message: ExponentialHistogram, writer: IBinaryWriter, options: BinaryWriteOptions): IBinaryWriter;\n}\n\n/**\n * ExponentialHistogram represents the type of a metric that is calculated by aggregating\n * as a ExponentialHistogram of all reported double measurements over a time interval.\n *\n * @generated from protobuf message opentelemetry.proto.metrics.v1.ExponentialHistogram\n */\nexport  interface ExponentialHistogram {\n    /**\n     * @generated from protobuf field: repeated opentelemetry.proto.metrics.v1.ExponentialHistogramDataPoint data_points = 1;\n     */\n    dataPoints: ExponentialHistogramDataPoint[];\n    /**\n     * aggregation_temporality describes if the aggregator reports delta changes\n     * since last report time, or cumulative changes since a fixed start time.\n     *\n     * @generated from protobuf field: opentelemetry.proto.metrics.v1.AggregationTemporality aggregation_temporality = 2;\n     */\n    aggregationTemporality: AggregationTemporality;\n}\n\n/**\n * @generated MessageType for protobuf message opentelemetry.proto.metrics.v1.ExponentialHistogram\n */\nexport  const ExponentialHistogram: ExponentialHistogram$Type;\n\nexport class ExponentialHistogramDataPoint$Type extends MessageType\u003cExponentialHistogramDataPoint\u003e {\n    constructor();\n    create(value?: PartialMessage\u003cExponentialHistogramDataPoint\u003e): ExponentialHistogramDataPoint;\n    internalBinaryRead(reader: IBinaryReader, length: number, options: BinaryReadOptions, target?: ExponentialHistogramDataPoint): ExponentialHistogramDataPoint;\n    internalBinaryWrite(message: ExponentialHistogramDataPoint, writer: IBinaryWriter, options: BinaryWriteOptions): IBinaryWriter;\n}\n\n/**\n * ExponentialHistogramDataPoint is a single data point in a timeseries that describes the\n * time-varying values of a ExponentialHistogram of double values. A ExponentialHistogram contains\n * summary statistics for a population of values, it may optionally contain the\n * distribution of those values across a set of buckets.\n *\n *\n * @generated from protobuf message opentelemetry.proto.metrics.v1.ExponentialHistogramDataPoint\n */\nexport  interface ExponentialHistogramDataPoint {\n    /**\n     * The set of key/value pairs that uniquely identify the timeseries from\n     * where this point belongs. The list may be empty (may contain 0 elements).\n     * Attribute keys MUST be unique (it is not allowed to have more than one\n     * attribute with the same key).\n     *\n     * @generated from protobuf field: repeated opentelemetry.proto.common.v1.KeyValue attributes = 1;\n     */\n    attributes: KeyValue[];\n    /**\n     * StartTimeUnixNano is optional but strongly encouraged, see the\n     * the detailed comments above Metric.\n     *\n     * Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January\n     * 1970.\n     *\n     * @generated from protobuf field: fixed64 start_time_unix_nano = 2;\n     */\n    startTimeUnixNano: number;\n    /**\n     * TimeUnixNano is required, see the detailed comments above Metric.\n     *\n     * Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January\n     * 1970.\n     *\n     * @generated from protobuf field: fixed64 time_unix_nano = 3;\n     */\n    timeUnixNano: number;\n    /**\n     * count is the number of values in the population. Must be\n     * non-negative. This value must be equal to the sum of the \"bucket_counts\"\n     * values in the positive and negative Buckets plus the \"zero_count\" field.\n     *\n     * @generated from protobuf field: fixed64 count = 4;\n     */\n    count: number;\n    /**\n     * sum of the values in the population. If count is zero then this field\n     * must be zero.\n     *\n     * Note: Sum should only be filled out when measuring non-negative discrete\n     * events, and is assumed to be monotonic over the values of these events.\n     * Negative events *can* be recorded, but sum should not be filled out when\n     * doing so.  This is specifically to enforce compatibility w/ OpenMetrics,\n     * see: https://github.com/OpenObservability/OpenMetrics/blob/main/specification/OpenMetrics.md#histogram\n     *\n     * @generated from protobuf field: optional double sum = 5;\n     */\n    sum?: number;\n    /**\n     * scale describes the resolution of the histogram.  Boundaries are\n     * located at powers of the base, where:\n     *\n     *   base = (2^(2^-scale))\n     *\n     * The histogram bucket identified by `index`, a signed integer,\n     * contains values that are greater than (base^index) and\n     * less than or equal to (base^(index+1)).\n     *\n     * The positive and negative ranges of the histogram are expressed\n     * separately.  Negative values are mapped by their absolute value\n     * into the negative range using the same scale as the positive range.\n     *\n     * scale is not restricted by the protocol, as the permissible\n     * values depend on the range of the data.\n     *\n     * @generated from protobuf field: sint32 scale = 6;\n     */\n    scale: number;\n    /**\n     * zero_count is the count of values that are either exactly zero or\n     * within the region considered zero by the instrumentation at the\n     * tolerated degree of precision.  This bucket stores values that\n     * cannot be expressed using the standard exponential formula as\n     * well as values that have been rounded to zero.\n     *\n     * Implementations MAY consider the zero bucket to have probability\n     * mass equal to (zero_count / count).\n     *\n     * @generated from protobuf field: fixed64 zero_count = 7;\n     */\n    zeroCount: number;\n    /**\n     * positive carries the positive range of exponential bucket counts.\n     *\n     * @generated from protobuf field: opentelemetry.proto.metrics.v1.ExponentialHistogramDataPoint.Buckets positive = 8;\n     */\n    positive?: ExponentialHistogramDataPoint_Buckets;\n    /**\n     * negative carries the negative range of exponential bucket counts.\n     *\n     * @generated from protobuf field: opentelemetry.proto.metrics.v1.ExponentialHistogramDataPoint.Buckets negative = 9;\n     */\n    negative?: ExponentialHistogramDataPoint_Buckets;\n    /**\n     * Flags that apply to this specific data point.  See DataPointFlags\n     * for the available flags and their meaning.\n     *\n     * @generated from protobuf field: uint32 flags = 10;\n     */\n    flags: number;\n    /**\n     * (Optional) List of exemplars collected from\n     * measurements that were used to form the data point\n     *\n     * @generated from protobuf field: repeated opentelemetry.proto.metrics.v1.Exemplar exemplars = 11;\n     */\n    exemplars: Exemplar[];\n    /**\n     * min is the minimum value over (start_time, end_time].\n     *\n     * @generated from protobuf field: optional double min = 12;\n     */\n    min?: number;\n    /**\n     * max is the maximum value over (start_time, end_time].\n     *\n     * @generated from protobuf field: optional double max = 13;\n     */\n    max?: number;\n    /**\n     * ZeroThreshold may be optionally set to convey the width of the zero\n     * region. Where the zero region is defined as the closed interval\n     * [-ZeroThreshold, ZeroThreshold].\n     * When ZeroThreshold is 0, zero count bucket stores values that cannot be\n     * expressed using the standard exponential formula as well as values that\n     * have been rounded to zero.\n     *\n     * @generated from protobuf field: double zero_threshold = 14;\n     */\n    zeroThreshold: number;\n}\n\n/**\n * @generated MessageType for protobuf message opentelemetry.proto.metrics.v1.ExponentialHistogramDataPoint\n */\nexport  const ExponentialHistogramDataPoint: ExponentialHistogramDataPoint$Type;\n\nexport class ExponentialHistogramDataPoint_Buckets$Type extends MessageType\u003cExponentialHistogramDataPoint_Buckets\u003e {\n    constructor();\n    create(value?: PartialMessage\u003cExponentialHistogramDataPoint_Buckets\u003e): ExponentialHistogramDataPoint_Buckets;\n    internalBinaryRead(reader: IBinaryReader, length: number, options: BinaryReadOptions, target?: ExponentialHistogramDataPoint_Buckets): ExponentialHistogramDataPoint_Buckets;\n    internalBinaryWrite(message: ExponentialHistogramDataPoint_Buckets, writer: IBinaryWriter, options: BinaryWriteOptions): IBinaryWriter;\n}\n\n/**\n * Buckets are a set of bucket counts, encoded in a contiguous array\n * of counts.\n *\n * @generated from protobuf message opentelemetry.proto.metrics.v1.ExponentialHistogramDataPoint.Buckets\n */\nexport  interface ExponentialHistogramDataPoint_Buckets {\n    /**\n     * Offset is the bucket index of the first entry in the bucket_counts array.\n     *\n     * Note: This uses a varint encoding as a simple form of compression.\n     *\n     * @generated from protobuf field: sint32 offset = 1;\n     */\n    offset: number;\n    /**\n     * bucket_counts is an array of count values, where bucket_counts[i] carries\n     * the count of the bucket at index (offset+i). bucket_counts[i] is the count\n     * of values greater than base^(offset+i) and less than or equal to\n     * base^(offset+i+1).\n     *\n     * Note: By contrast, the explicit HistogramDataPoint uses\n     * fixed64.  This field is expected to have many buckets,\n     * especially zeros, so uint64 has been selected to ensure\n     * varint encoding.\n     *\n     * @generated from protobuf field: repeated uint64 bucket_counts = 2;\n     */\n    bucketCounts: number[];\n}\n\n/**\n * @generated MessageType for protobuf message opentelemetry.proto.metrics.v1.ExponentialHistogramDataPoint.Buckets\n */\nexport  const ExponentialHistogramDataPoint_Buckets: ExponentialHistogramDataPoint_Buckets$Type;\n\n/**\n * Describes a field of a protobuf message for runtime\n * reflection. We distinguish between the following\n * kinds of fields:\n *\n * \"scalar\": string, bool, float, int32, etc.\n * See https://developers.google.com/protocol-buffers/docs/proto3#scalar\n *\n * \"enum\": field was declared with an enum type.\n *\n * \"message\": field was declared with a message type.\n *\n * \"map\": field was declared with map\u003cK,V\u003e.\n *\n *\n * Every field, regardless of it's kind, always has the following properties:\n *\n * \"no\": The field number of the .proto field.\n * \"name\": The original name of the .proto field.\n * \"localName\": The name of the field as used in generated code.\n * \"jsonName\": The name for JSON serialization / deserialization.\n * \"options\": Custom field options from the .proto source in JSON format.\n *\n *\n * Other properties:\n *\n * - Fields of kind \"scalar\", \"enum\" and \"message\" can have a \"repeat\" type.\n * - Fields of kind \"scalar\" and \"enum\" can have a \"repeat\" type.\n * - Fields of kind \"scalar\", \"enum\" and \"message\" can be member of a \"oneof\".\n *\n * A field can be only have one of the above properties set.\n *\n * Options for \"scalar\" fields:\n *\n * - 64 bit integral types can provide \"L\" - the JavaScript representation\n *   type.\n *\n */\nexport type FieldInfo = fiRules\u003cfiScalar\u003e | fiRules\u003cfiEnum\u003e | fiRules\u003cfiMessage\u003e | fiRules\u003cfiMap\u003e;\n\nexport interface fiEnum extends fiShared {\n    kind: 'enum';\n    /**\n     * Enum type information for the field.\n     */\n    T: () =\u003e EnumInfo;\n    /**\n     * Is the field repeated?\n     */\n    repeat: RepeatType;\n    /**\n     * Is the field optional?\n     */\n    opt: boolean;\n}\n\nexport interface fiMap extends fiShared {\n    kind: 'map';\n    /**\n     * Map key type.\n     *\n     * The key_type can be any integral or string type\n     * (so, any scalar type except for floating point\n     * types and bytes)\n     */\n    K: Exclude\u003cScalarType, ScalarType.FLOAT | ScalarType.DOUBLE | ScalarType.BYTES\u003e;\n    /**\n     * Map value type. Can be a `ScalarType`, enum type information,\n     * or type handler for a message.\n     */\n    V: {\n        kind: 'scalar';\n        T: ScalarType;\n        L?: LongType;\n    } | {\n        kind: 'enum';\n        T: () =\u003e EnumInfo;\n    } | {\n        kind: 'message';\n        T: () =\u003e IMessageType\u003cany\u003e;\n    };\n}\n\nexport interface fiMessage extends fiShared {\n    kind: 'message';\n    /**\n     * Message handler for the field.\n     */\n    T: () =\u003e IMessageType\u003cany\u003e;\n    /**\n     * Is the field repeated?\n     */\n    repeat: RepeatType;\n}\n\nexport type fiPartialRules\u003cT\u003e = Omit\u003cT, 'jsonName' | 'localName' | 'oneof' | 'repeat' | 'opt'\u003e \u0026 ({\n    localName?: string;\n    jsonName?: string;\n    repeat?: RepeatType.NO;\n    opt?: false;\n    oneof?: undefined;\n} | {\n    localName?: string;\n    jsonName?: string;\n    repeat?: RepeatType.NO;\n    opt: true;\n    oneof?: undefined;\n} | {\n    localName?: string;\n    jsonName?: string;\n    repeat: RepeatType.PACKED | RepeatType.UNPACKED;\n    opt?: false;\n    oneof?: undefined;\n} | {\n    localName?: string;\n    jsonName?: string;\n    repeat?: RepeatType.NO;\n    opt?: false;\n    oneof: string;\n});\n\nexport type fiRules\u003cT\u003e = Omit\u003cT, 'oneof' | 'repeat' | 'opt'\u003e \u0026 ({\n    repeat: RepeatType.NO;\n    opt: false;\n    oneof: undefined;\n} | {\n    repeat: RepeatType.NO;\n    opt: true;\n    oneof: undefined;\n} | {\n    repeat: RepeatType.PACKED | RepeatType.UNPACKED;\n    opt: false;\n    oneof: undefined;\n} | {\n    repeat: RepeatType.NO;\n    opt: false;\n    oneof: string;\n});\n\nexport interface fiScalar extends fiShared {\n    kind: 'scalar';\n    /**\n     * Scalar type of the field.\n     */\n    T: ScalarType;\n    /**\n     * Representation of 64 bit integral types (int64, uint64, sint64,\n     * fixed64, sfixed64).\n     *\n     * If this option is set for other scalar types, it is ignored.\n     * Omitting this option is equivalent to `STRING`.\n     */\n    L?: LongType;\n    /**\n     * Is the field repeated?\n     */\n    repeat: RepeatType;\n    /**\n     * Is the field optional?\n     */\n    opt: boolean;\n}\n\nexport interface fiShared {\n    /**\n     * The field number of the .proto field.\n     */\n    no: number;\n    /**\n     * The original name of the .proto field.\n     */\n    name: string;\n    /**\n     * The name of the field as used in generated code.\n     */\n    localName: string;\n    /**\n     * The name for JSON serialization / deserialization.\n     */\n    jsonName: string;\n    /**\n     * The name of the `oneof` group, if this field belongs to one.\n     */\n    oneof: string | undefined;\n    /**\n     * Contains custom field options from the .proto source in JSON format.\n     */\n    options?: {\n        [extensionName: string]: JsonValue;\n    };\n}\n\nexport class Gauge$Type extends MessageType\u003cGauge\u003e {\n    constructor();\n    create(value?: PartialMessage\u003cGauge\u003e): Gauge;\n    internalBinaryRead(reader: IBinaryReader, length: number, options: BinaryReadOptions, target?: Gauge): Gauge;\n    internalBinaryWrite(message: Gauge, writer: IBinaryWriter, options: BinaryWriteOptions): IBinaryWriter;\n}\n\n/**\n * Gauge represents the type of a scalar metric that always exports the\n * \"current value\" for every data point. It should be used for an \"unknown\"\n * aggregation.\n *\n * A Gauge does not support different aggregation temporalities. Given the\n * aggregation is unknown, points cannot be combined using the same\n * aggregation, regardless of aggregation temporalities. Therefore,\n * AggregationTemporality is not included. Consequently, this also means\n * \"StartTimeUnixNano\" is ignored for all data points.\n *\n * @generated from protobuf message opentelemetry.proto.metrics.v1.Gauge\n */\nexport  interface Gauge {\n    /**\n     * @generated from protobuf field: repeated opentelemetry.proto.metrics.v1.NumberDataPoint data_points = 1;\n     */\n    dataPoints: NumberDataPoint[];\n}\n\n/**\n * @generated MessageType for protobuf message opentelemetry.proto.metrics.v1.Gauge\n */\nexport  const Gauge: Gauge$Type;\n\nexport class Histogram$Type extends MessageType\u003cHistogram\u003e {\n    constructor();\n    create(value?: PartialMessage\u003cHistogram\u003e): Histogram;\n    internalBinaryRead(reader: IBinaryReader, length: number, options: BinaryReadOptions, target?: Histogram): Histogram;\n    internalBinaryWrite(message: Histogram, writer: IBinaryWriter, options: BinaryWriteOptions): IBinaryWriter;\n}\n\n/**\n * Histogram represents the type of a metric that is calculated by aggregating\n * as a Histogram of all reported measurements over a time interval.\n *\n * @generated from protobuf message opentelemetry.proto.metrics.v1.Histogram\n */\nexport  interface Histogram {\n    /**\n     * @generated from protobuf field: repeated opentelemetry.proto.metrics.v1.HistogramDataPoint data_points = 1;\n     */\n    dataPoints: HistogramDataPoint[];\n    /**\n     * aggregation_temporality describes if the aggregator reports delta changes\n     * since last report time, or cumulative changes since a fixed start time.\n     *\n     * @generated from protobuf field: opentelemetry.proto.metrics.v1.AggregationTemporality aggregation_temporality = 2;\n     */\n    aggregationTemporality: AggregationTemporality;\n}\n\n/**\n * @generated MessageType for protobuf message opentelemetry.proto.metrics.v1.Histogram\n */\nexport  const Histogram: Histogram$Type;\n\nexport class HistogramDataPoint$Type extends MessageType\u003cHistogramDataPoint\u003e {\n    constructor();\n    create(value?: PartialMessage\u003cHistogramDataPoint\u003e): HistogramDataPoint;\n    internalBinaryRead(reader: IBinaryReader, length: number, options: BinaryReadOptions, target?: HistogramDataPoint): HistogramDataPoint;\n    internalBinaryWrite(message: HistogramDataPoint, writer: IBinaryWriter, options: BinaryWriteOptions): IBinaryWriter;\n}\n\n/**\n * HistogramDataPoint is a single data point in a timeseries that describes the\n * time-varying values of a Histogram. A Histogram contains summary statistics\n * for a population of values, it may optionally contain the distribution of\n * those values across a set of buckets.\n *\n * If the histogram contains the distribution of values, then both\n * \"explicit_bounds\" and \"bucket counts\" fields must be defined.\n * If the histogram does not contain the distribution of values, then both\n * \"explicit_bounds\" and \"bucket_counts\" must be omitted and only \"count\" and\n * \"sum\" are known.\n *\n * @generated from protobuf message opentelemetry.proto.metrics.v1.HistogramDataPoint\n */\nexport  interface HistogramDataPoint {\n    /**\n     * The set of key/value pairs that uniquely identify the timeseries from\n     * where this point belongs. The list may be empty (may contain 0 elements).\n     * Attribute keys MUST be unique (it is not allowed to have more than one\n     * attribute with the same key).\n     *\n     * @generated from protobuf field: repeated opentelemetry.proto.common.v1.KeyValue attributes = 9;\n     */\n    attributes: KeyValue[];\n    /**\n     * StartTimeUnixNano is optional but strongly encouraged, see the\n     * the detailed comments above Metric.\n     *\n     * Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January\n     * 1970.\n     *\n     * @generated from protobuf field: fixed64 start_time_unix_nano = 2;\n     */\n    startTimeUnixNano: number;\n    /**\n     * TimeUnixNano is required, see the detailed comments above Metric.\n     *\n     * Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January\n     * 1970.\n     *\n     * @generated from protobuf field: fixed64 time_unix_nano = 3;\n     */\n    timeUnixNano: number;\n    /**\n     * count is the number of values in the population. Must be non-negative. This\n     * value must be equal to the sum of the \"count\" fields in buckets if a\n     * histogram is provided.\n     *\n     * @generated from protobuf field: fixed64 count = 4;\n     */\n    count: number;\n    /**\n     * sum of the values in the population. If count is zero then this field\n     * must be zero.\n     *\n     * Note: Sum should only be filled out when measuring non-negative discrete\n     * events, and is assumed to be monotonic over the values of these events.\n     * Negative events *can* be recorded, but sum should not be filled out when\n     * doing so.  This is specifically to enforce compatibility w/ OpenMetrics,\n     * see: https://github.com/OpenObservability/OpenMetrics/blob/main/specification/OpenMetrics.md#histogram\n     *\n     * @generated from protobuf field: optional double sum = 5;\n     */\n    sum?: number;\n    /**\n     * bucket_counts is an optional field contains the count values of histogram\n     * for each bucket.\n     *\n     * The sum of the bucket_counts must equal the value in the count field.\n     *\n     * The number of elements in bucket_counts array must be by one greater than\n     * the number of elements in explicit_bounds array.\n     *\n     * @generated from protobuf field: repeated fixed64 bucket_counts = 6;\n     */\n    bucketCounts: number[];\n    /**\n     * explicit_bounds specifies buckets with explicitly defined bounds for values.\n     *\n     * The boundaries for bucket at index i are:\n     *\n     * (-infinity, explicit_bounds[i]] for i == 0\n     * (explicit_bounds[i-1], explicit_bounds[i]] for 0 \u003c i \u003c size(explicit_bounds)\n     * (explicit_bounds[i-1], +infinity) for i == size(explicit_bounds)\n     *\n     * The values in the explicit_bounds array must be strictly increasing.\n     *\n     * Histogram buckets are inclusive of their upper boundary, except the last\n     * bucket where the boundary is at infinity. This format is intentionally\n     * compatible with the OpenMetrics histogram definition.\n     *\n     * @generated from protobuf field: repeated double explicit_bounds = 7;\n     */\n    explicitBounds: number[];\n    /**\n     * (Optional) List of exemplars collected from\n     * measurements that were used to form the data point\n     *\n     * @generated from protobuf field: repeated opentelemetry.proto.metrics.v1.Exemplar exemplars = 8;\n     */\n    exemplars: Exemplar[];\n    /**\n     * Flags that apply to this specific data point.  See DataPointFlags\n     * for the available flags and their meaning.\n     *\n     * @generated from protobuf field: uint32 flags = 10;\n     */\n    flags: number;\n    /**\n     * min is the minimum value over (start_time, end_time].\n     *\n     * @generated from protobuf field: optional double min = 11;\n     */\n    min?: number;\n    /**\n     * max is the maximum value over (start_time, end_time].\n     *\n     * @generated from protobuf field: optional double max = 12;\n     */\n    max?: number;\n}\n\n/**\n * @generated MessageType for protobuf message opentelemetry.proto.metrics.v1.HistogramDataPoint\n */\nexport  const HistogramDataPoint: HistogramDataPoint$Type;\n\n/**\n * This interface is used throughout @protobuf-ts to read\n * protobuf binary format.\n *\n * While not completely compatible, this interface is closely aligned\n * with the `Reader` class of `protobufjs` to make it easier to swap\n * the implementation.\n */\nexport interface IBinaryReader {\n    /**\n     * Current position.\n     */\n    readonly pos: number;\n    /**\n     * Number of bytes available in this reader.\n     */\n    readonly len: number;\n    /**\n     * Reads a tag - field number and wire type.\n     */\n    tag(): [number, WireType];\n    /**\n     * Skip one element on the wire and return the skipped data.\n     */\n    skip(wireType: WireType): Uint8Array;\n    /**\n     * Read a `int32` field, a signed 32 bit varint.\n     */\n    uint32(): number;\n    /**\n     * Read a `sint32` field, a signed, zigzag-encoded 32-bit varint.\n     */\n    int32(): number;\n    /**\n     * Read a `sint32` field, a signed, zigzag-encoded 32-bit varint.\n     */\n    sint32(): number;\n    /**\n     * Read a `int64` field, a signed 64-bit varint.\n     */\n    int64(): PbLong;\n    /**\n     * Read a `sint64` field, a signed, zig-zag-encoded 64-bit varint.\n     */\n    sint64(): PbLong;\n    /**\n     * Read a `fixed64` field, a signed, fixed-length 64-bit integer.\n     */\n    sfixed64(): PbLong;\n    /**\n     * Read a `uint64` field, an unsigned 64-bit varint.\n     */\n    uint64(): PbULong;\n    /**\n     * Read a `fixed64` field, an unsigned, fixed-length 64 bit integer.\n     */\n    fixed64(): PbULong;\n    /**\n     * Read a `bool` field, a variant.\n     */\n    bool(): boolean;\n    /**\n     * Read a `fixed32` field, an unsigned, fixed-length 32-bit integer.\n     */\n    fixed32(): number;\n    /**\n     * Read a `sfixed32` field, a signed, fixed-length 32-bit integer.\n     */\n    sfixed32(): number;\n    /**\n     * Read a `float` field, 32-bit floating point number.\n     */\n    float(): number;\n    /**\n     * Read a `double` field, a 64-bit floating point number.\n     */\n    double(): number;\n    /**\n     * Read a `bytes` field, length-delimited arbitrary data.\n     */\n    bytes(): Uint8Array;\n    /**\n     * Read a `string` field, length-delimited data converted to UTF-8 text.\n     */\n    string(): string;\n}\n\n/**\n * This interface is used throughout @protobuf-ts to write\n * protobuf binary format.\n *\n * While not completely compatible, this interface is closely aligned\n * with the `Writer` class of `protobufjs` to make it easier to swap\n * the implementation.\n */\nexport interface IBinaryWriter {\n    /**\n     * Return all bytes written and reset this writer.\n     */\n    finish(): Uint8Array;\n    /**\n     * Start a new fork for length-delimited data like a message\n     * or a packed repeated field.\n     *\n     * Must be joined later with `join()`.\n     */\n    fork(): IBinaryWriter;\n    /**\n     * Join the last fork. Write its length and bytes, then\n     * return to the previous state.\n     */\n    join(): IBinaryWriter;\n    /**\n     * Writes a tag (field number and wire type).\n     *\n     * Equivalent to `uint32( (fieldNo \u003c\u003c 3 | type) \u003e\u003e\u003e 0 )`\n     *\n     * Generated code should compute the tag ahead of time and call `uint32()`.\n     */\n    tag(fieldNo: number, type: WireType): IBinaryWriter;\n    /**\n     * Write a chunk of raw bytes.\n     */\n    raw(chunk: Uint8Array): IBinaryWriter;\n    /**\n     * Write a `uint32` value, an unsigned 32 bit varint.\n     */\n    uint32(value: number): IBinaryWriter;\n    /**\n     * Write a `int32` value, a signed 32 bit varint.\n     */\n    int32(value: number): IBinaryWriter;\n    /**\n     * Write a `sint32` value, a signed, zigzag-encoded 32-bit varint.\n     */\n    sint32(value: number): IBinaryWriter;\n    /**\n     * Write a `int64` value, a signed 64-bit varint.\n     */\n    int64(value: string | number | bigint): IBinaryWriter;\n    /**\n     * Write a `uint64` value, an unsigned 64-bit varint.\n     */\n    uint64(value: string | number | bigint): IBinaryWriter;\n    /**\n     * Write a `sint64` value, a signed, zig-zag-encoded 64-bit varint.\n     */\n    sint64(value: string | number | bigint): IBinaryWriter;\n    /**\n     * Write a `fixed64` value, an unsigned, fixed-length 64 bit integer.\n     */\n    fixed64(value: string | number | bigint): IBinaryWriter;\n    /**\n     * Write a `fixed64` value, a signed, fixed-length 64-bit integer.\n     */\n    sfixed64(value: string | number | bigint): IBinaryWriter;\n    /**\n     * Write a `bool` value, a variant.\n     */\n    bool(value: boolean): IBinaryWriter;\n    /**\n     * Write a `fixed32` value, an unsigned, fixed-length 32-bit integer.\n     */\n    fixed32(value: number): IBinaryWriter;\n    /**\n     * Write a `sfixed32` value, a signed, fixed-length 32-bit integer.\n     */\n    sfixed32(value: number): IBinaryWriter;\n    /**\n     * Write a `float` value, 32-bit floating point number.\n     */\n    float(value: number): IBinaryWriter;\n    /**\n     * Write a `double` value, a 64-bit floating point number.\n     */\n    double(value: number): IBinaryWriter;\n    /**\n     * Write a `bytes` value, length-delimited arbitrary data.\n     */\n    bytes(value: Uint8Array): IBinaryWriter;\n    /**\n     * Write a `string` value, length-delimited data converted to UTF-8 text.\n     */\n    string(value: string): IBinaryWriter;\n}\n\n/**\n * A message type provides an API to work with messages of a specific type.\n * It also exposes reflection information that can be used to work with a\n * message of unknown type.\n */\nexport interface IMessageType\u003cT extends object\u003e extends MessageInfo {\n    /**\n     * The protobuf type name of the message, including package and\n     * parent types if present.\n     *\n     * Examples:\n     * 'MyNamespaceLessMessage'\n     * 'my_package.MyMessage'\n     * 'my_package.ParentMessage.ChildMessage'\n     */\n    readonly typeName: string;\n    /**\n     * Simple information for each message field, in the order\n     * of declaration in the .proto.\n     */\n    readonly fields: readonly FieldInfo[];\n    /**\n     * Contains custom message options from the .proto source in JSON format.\n     */\n    readonly options: {\n        [extensionName: string]: JsonValue;\n    };\n    /**\n     * Contains the prototype for messages returned by create() which\n     * includes the `MESSAGE_TYPE` symbol pointing back to `this`.\n     */\n    readonly messagePrototype?: Readonly\u003c{}\u003e | undefined;\n    /**\n     * Create a new message with default values.\n     *\n     * For example, a protobuf `string name = 1;` has the default value `\"\"`.\n     */\n    create(): T;\n    /**\n     * Create a new message from partial data.\n     *\n     * Unknown fields are discarded.\n     *\n     * `PartialMessage\u003cT\u003e` is similar to `Partial\u003cT\u003e`,\n     * but it is recursive, and it keeps `oneof` groups\n     * intact.\n     */\n    create(value: PartialMessage\u003cT\u003e): T;\n    /**\n     * Create a new message from binary format.\n     */\n    fromBinary(data: Uint8Array, options?: Partial\u003cBinaryReadOptions\u003e): T;\n    /**\n     * Write the message to binary format.\n     */\n    toBinary(message: T, options?: Partial\u003cBinaryWriteOptions\u003e): Uint8Array;\n    /**\n     * Read a new message from a JSON value.\n     */\n    fromJson(json: JsonValue, options?: Partial\u003cJsonReadOptions\u003e): T;\n    /**\n     * Read a new message from a JSON string.\n     * This is equivalent to `T.fromJson(JSON.parse(json))`.\n     */\n    fromJsonString(json: string, options?: Partial\u003cJsonReadOptions\u003e): T;\n    /**\n     * Convert the message to canonical JSON value.\n     */\n    toJson(message: T, options?: Partial\u003cJsonWriteOptions\u003e): JsonValue;\n    /**\n     * Convert the message to canonical JSON string.\n     * This is equivalent to `JSON.stringify(T.toJson(t))`\n     */\n    toJsonString(message: T, options?: Partial\u003cJsonWriteStringOptions\u003e): string;\n    /**\n     * Clone the message.\n     *\n     * Unknown fields are discarded.\n     */\n    clone(message: T): T;\n    /**\n     * Copy partial data into the target message.\n     *\n     * If a singular scalar or enum field is present in the source, it\n     * replaces the field in the target.\n     *\n     * If a singular message field is present in the source, it is merged\n     * with the target field by calling mergePartial() of the responsible\n     * message type.\n     *\n     * If a repeated field is present in the source, its values replace\n     * all values in the target array, removing extraneous values.\n     * Repeated message fields are copied, not merged.\n     *\n     * If a map field is present in the source, entries are added to the\n     * target map, replacing entries with the same key. Entries that only\n     * exist in the target remain. Entries with message values are copied,\n     * not merged.\n     *\n     * Note that this function differs from protobuf merge semantics,\n     * which appends repeated fields.\n     */\n    mergePartial(target: T, source: PartialMessage\u003cT\u003e): void;\n    /**\n     * Determines whether two message of the same type have the same field values.\n     * Checks for deep equality, traversing repeated fields, oneof groups, maps\n     * and messages recursively.\n     * Will also return true if both messages are `undefined`.\n     */\n    equals(a: T | undefined, b: T | undefined): boolean;\n    /**\n     * Is the given value assignable to our message type\n     * and contains no [excess properties](https://www.typescriptlang.org/docs/handbook/interfaces.html#excess-property-checks)?\n     */\n    is(arg: any, depth?: number): arg is T;\n    /**\n     * Is the given value assignable to our message type,\n     * regardless of [excess properties](https://www.typescriptlang.org/docs/handbook/interfaces.html#excess-property-checks)?\n     */\n    isAssignable(arg: any, depth?: number): arg is T;\n    /**\n     * This is an internal method. If you just want to read a message from\n     * JSON, use `fromJson()` or `fromJsonString()`.\n     *\n     * Reads JSON value and merges the fields into the target\n     * according to protobuf rules. If the target is omitted,\n     * a new instance is created first.\n     */\n    internalJsonRead(json: JsonValue, options: JsonReadOptions, target?: T): T;\n    /**\n     * This is an internal method. If you just want to write a message\n     * to JSON, use `toJson()` or `toJsonString().\n     *\n     * Writes JSON value and returns it.\n     */\n    internalJsonWrite(message: T, options: JsonWriteOptions): JsonValue;\n    /**\n     * This is an internal method. If you just want to write a message\n     * in binary format, use `toBinary()`.\n     *\n     * Serializes the message in binary format and appends it to the given\n     * writer. Returns passed writer.\n     */\n    internalBinaryWrite(message: T, writer: IBinaryWriter, options: BinaryWriteOptions): IBinaryWriter;\n    /**\n     * This is an internal method. If you just want to read a message from\n     * binary data, use `fromBinary()`.\n     *\n     * Reads data from binary format and merges the fields into\n     * the target according to protobuf rules. If the target is\n     * omitted, a new instance is created first.\n     */\n    internalBinaryRead(reader: IBinaryReader, length: number, options: BinaryReadOptions, target?: T): T;\n}\n\nexport class InstrumentationScope$Type extends MessageType\u003cInstrumentationScope\u003e {\n    constructor();\n    create(value?: PartialMessage\u003cInstrumentationScope\u003e): InstrumentationScope;\n    internalBinaryRead(reader: IBinaryReader, length: number, options: BinaryReadOptions, target?: InstrumentationScope): InstrumentationScope;\n    internalBinaryWrite(message: InstrumentationScope, writer: IBinaryWriter, options: BinaryWriteOptions): IBinaryWriter;\n}\n\n/**\n * InstrumentationScope is a message representing the instrumentation scope information\n * such as the fully qualified name and version.\n *\n * @generated from protobuf message opentelemetry.proto.common.v1.InstrumentationScope\n */\nexport  interface InstrumentationScope {\n    /**\n     * An empty instrumentation scope name means the name is unknown.\n     *\n     * @generated from protobuf field: string name = 1;\n     */\n    name: string;\n    /**\n     * @generated from protobuf field: string version = 2;\n     */\n    version: string;\n    /**\n     * Additional attributes that describe the scope. [Optional].\n     * Attribute keys MUST be unique (it is not allowed to have more than one\n     * attribute with the same key).\n     *\n     * @generated from protobuf field: repeated opentelemetry.proto.common.v1.KeyValue attributes = 3;\n     */\n    attributes: KeyValue[];\n    /**\n     * @generated from protobuf field: uint32 dropped_attributes_count = 4;\n     */\n    droppedAttributesCount: number;\n}\n\n/**\n * @generated MessageType for protobuf message opentelemetry.proto.common.v1.InstrumentationScope\n */\nexport  const InstrumentationScope: InstrumentationScope$Type;\n\nexport interface JsonArray extends Array\u003cJsonValue\u003e {\n}\n\n/**\n * Represents a JSON object.\n */\nexport type JsonObject = {\n    [k: string]: JsonValue;\n};\n\nexport type JsonOptionsMap = {\n    [extensionName: string]: JsonValue;\n};\n\n/**\n * Options for parsing JSON data.\n * All boolean options default to `false`.\n */\nexport interface JsonReadOptions {\n    /**\n     * Ignore unknown fields: Proto3 JSON parser should reject unknown fields\n     * by default. This option ignores unknown fields in parsing, as well as\n     * unrecognized enum string representations.\n     */\n    ignoreUnknownFields: boolean;\n    /**\n     * This option is required to read `google.protobuf.Any`\n     * from JSON format.\n     */\n    typeRegistry?: readonly IMessageType\u003cany\u003e[];\n}\n\n/**\n * Represents any possible JSON value:\n * - number\n * - string\n * - boolean\n * - null\n * - object (with any JSON value as property)\n * - array (with any JSON value as element)\n */\nexport type JsonValue = number | string | boolean | null | JsonObject | JsonArray;\n\n/**\n * Options for serializing to JSON object.\n * All boolean options default to `false`.\n */\nexport interface JsonWriteOptions {\n    /**\n     * Emit fields with default values: Fields with default values are omitted\n     * by default in proto3 JSON output. This option overrides this behavior\n     * and outputs fields with their default values.\n     */\n    emitDefaultValues: boolean;\n    /**\n     * Emit enum values as integers instead of strings: The name of an enum\n     * value is used by default in JSON output. An option may be provided to\n     * use the numeric value of the enum value instead.\n     */\n    enumAsInteger: boolean;\n    /**\n     * Use proto field name instead of lowerCamelCase name: By default proto3\n     * JSON printer should convert the field name to lowerCamelCase and use\n     * that as the JSON name. An implementation may provide an option to use\n     * proto field name as the JSON name instead. Proto3 JSON parsers are\n     * required to accept both the converted lowerCamelCase name and the proto\n     * field name.\n     */\n    useProtoFieldName: boolean;\n    /**\n     * This option is required to write `google.protobuf.Any`\n     * to JSON format.\n     */\n    typeRegistry?: readonly IMessageType\u003cany\u003e[];\n}\n\n/**\n * Options for serializing to JSON string.\n * All options default to `false` or `0`.\n */\nexport interface JsonWriteStringOptions extends JsonWriteOptions {\n    prettySpaces: number;\n}\n\nexport class KeyValue$Type extends MessageType\u003cKeyValue\u003e {\n    constructor();\n    create(value?: PartialMessage\u003cKeyValue\u003e): KeyValue;\n    internalBinaryRead(reader: IBinaryReader, length: number, options: BinaryReadOptions, target?: KeyValue): KeyValue;\n    internalBinaryWrite(message: KeyValue, writer: IBinaryWriter, options: BinaryWriteOptions): IBinaryWriter;\n}\n\n/**\n * KeyValue is a key-value pair that is used to store Span attributes, Link\n * attributes, etc.\n *\n * @generated from protobuf message opentelemetry.proto.common.v1.KeyValue\n */\nexport  interface KeyValue {\n    /**\n     * @generated from protobuf field: string key = 1;\n     */\n    key: string;\n    /**\n     * @generated from protobuf field: opentelemetry.proto.common.v1.AnyValue value = 2;\n     */\n    value?: AnyValue;\n}\n\n/**\n * @generated MessageType for protobuf message opentelemetry.proto.common.v1.KeyValue\n */\nexport  const KeyValue: KeyValue$Type;\n\nexport class KeyValueList$Type extends MessageType\u003cKeyValueList\u003e {\n    constructor();\n    create(value?: PartialMessage\u003cKeyValueList\u003e): KeyValueList;\n    internalBinaryRead(reader: IBinaryReader, length: number, options: BinaryReadOptions, target?: KeyValueList): KeyValueList;\n    internalBinaryWrite(message: KeyValueList, writer: IBinaryWriter, options: BinaryWriteOptions): IBinaryWriter;\n}\n\n/**\n * KeyValueList is a list of KeyValue messages. We need KeyValueList as a message\n * since `oneof` in AnyValue does not allow repeated fields. Everywhere else where we need\n * a list of KeyValue messages (e.g. in Span) we use `repeated KeyValue` directly to\n * avoid unnecessary extra wrapping (which slows down the protocol). The 2 approaches\n * are semantically equivalent.\n *\n * @generated from protobuf message opentelemetry.proto.common.v1.KeyValueList\n */\nexport  interface KeyValueList {\n    /**\n     * A collection of key/value pairs of key-value pairs. The list may be empty (may\n     * contain 0 elements).\n     * The keys MUST be unique (it is not allowed to have more than one\n     * value with the same key).\n     *\n     * @generated from protobuf field: repeated opentelemetry.proto.common.v1.KeyValue values = 1;\n     */\n    values: KeyValue[];\n}\n\n/**\n * @generated MessageType for protobuf message opentelemetry.proto.common.v1.KeyValueList\n */\nexport  const KeyValueList: KeyValueList$Type;\n\nexport class ListValue$Type extends MessageType\u003cListValue\u003e {\n    constructor();\n    /**\n     * Encode `ListValue` to JSON array.\n     */\n    internalJsonWrite(message: ListValue, options: JsonWriteOptions): JsonValue;\n    /**\n     * Decode `ListValue` from JSON array.\n     */\n    internalJsonRead(json: JsonValue, options: JsonReadOptions, target?: ListValue): ListValue;\n}\n\n/**\n * `ListValue` is a wrapper around a repeated field of values.\n *\n * The JSON representation for `ListValue` is JSON array.\n *\n * @generated from protobuf message google.protobuf.ListValue\n */\nexport interface ListValue {\n    /**\n     * Repeated field of dynamically typed values.\n     *\n     * @generated from protobuf field: repeated google.protobuf.Value values = 1;\n     */\n    values: Value[];\n}\n\n/**\n * @generated MessageType for protobuf message google.protobuf.ListValue\n */\nexport const ListValue: ListValue$Type;\n\nexport class LogRecord$Type extends MessageType\u003cLogRecord\u003e {\n    constructor();\n    create(value?: PartialMessage\u003cLogRecord\u003e): LogRecord;\n    internalBinaryRead(reader: IBinaryReader, length: number, options: BinaryReadOptions, target?: LogRecord): LogRecord;\n    internalBinaryWrite(message: LogRecord, writer: IBinaryWriter, options: BinaryWriteOptions): IBinaryWriter;\n}\n\n/**\n * A log record according to OpenTelemetry Log Data Model:\n * https://github.com/open-telemetry/oteps/blob/main/text/logs/0097-log-data-model.md\n *\n * @generated from protobuf message opentelemetry.proto.logs.v1.LogRecord\n */\nexport  interface LogRecord {\n    /**\n     * time_unix_nano is the time when the event occurred.\n     * Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January 1970.\n     * Value of 0 indicates unknown or missing timestamp.\n     *\n     * @generated from protobuf field: fixed64 time_unix_nano = 1;\n     */\n    timeUnixNano: number;\n    /**\n     * Time when the event was observed by the collection system.\n     * For events that originate in OpenTelemetry (e.g. using OpenTelemetry Logging SDK)\n     * this timestamp is typically set at the generation time and is equal to Timestamp.\n     * For events originating externally and collected by OpenTelemetry (e.g. using\n     * Collector) this is the time when OpenTelemetry's code observed the event measured\n     * by the clock of the OpenTelemetry code. This field MUST be set once the event is\n     * observed by OpenTelemetry.\n     *\n     * For converting OpenTelemetry log data to formats that support only one timestamp or\n     * when receiving OpenTelemetry log data by recipients that support only one timestamp\n     * internally the following logic is recommended:\n     *   - Use time_unix_nano if it is present, otherwise use observed_time_unix_nano.\n     *\n     * Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January 1970.\n     * Value of 0 indicates unknown or missing timestamp.\n     *\n     * @generated from protobuf field: fixed64 observed_time_unix_nano = 11;\n     */\n    observedTimeUnixNano: number;\n    /**\n     * Numerical value of the severity, normalized to values described in Log Data Model.\n     * [Optional].\n     *\n     * @generated from protobuf field: opentelemetry.proto.logs.v1.SeverityNumber severity_number = 2;\n     */\n    severityNumber: SeverityNumber;\n    /**\n     * The severity text (also known as log level). The original string representation as\n     * it is known at the source. [Optional].\n     *\n     * @generated from protobuf field: string severity_text = 3;\n     */\n    severityText: string;\n    /**\n     * A value containing the body of the log record. Can be for example a human-readable\n     * string message (including multi-line) describing the event in a free form or it can\n     * be a structured data composed of arrays and maps of other values. [Optional].\n     *\n     * @generated from protobuf field: opentelemetry.proto.common.v1.AnyValue body = 5;\n     */\n    body?: AnyValue;\n    /**\n     * Additional attributes that describe the specific event occurrence. [Optional].\n     * Attribute keys MUST be unique (it is not allowed to have more than one\n     * attribute with the same key).\n     *\n     * @generated from protobuf field: repeated opentelemetry.proto.common.v1.KeyValue attributes = 6;\n     */\n    attributes: KeyValue[];\n    /**\n     * @generated from protobuf field: uint32 dropped_attributes_count = 7;\n     */\n    droppedAttributesCount: number;\n    /**\n     * Flags, a bit field. 8 least significant bits are the trace flags as\n     * defined in W3C Trace Context specification. 24 most significant bits are reserved\n     * and must be set to 0. Readers must not assume that 24 most significant bits\n     * will be zero and must correctly mask the bits when reading 8-bit trace flag (use\n     * flags \u0026 LOG_RECORD_FLAGS_TRACE_FLAGS_MASK). [Optional].\n     *\n     * @generated from protobuf field: fixed32 flags = 8;\n     */\n    flags: number;\n    /**\n     * A unique identifier for a trace. All logs from the same trace share\n     * the same `trace_id`. The ID is a 16-byte array. An ID with all zeroes OR\n     * of length other than 16 bytes is considered invalid (empty string in OTLP/JSON\n     * is zero-length and thus is also invalid).\n     *\n     * This field is optional.\n     *\n     * The receivers SHOULD assume that the log record is not associated with a\n     * trace if any of the following is true:\n     *   - the field is not present,\n     *   - the field contains an invalid value.\n     *\n     * @generated from protobuf field: bytes trace_id = 9;\n     */\n    traceId: Uint8Array;\n    /**\n     * A unique identifier for a span within a trace, assigned when the span\n     * is created. The ID is an 8-byte array. An ID with all zeroes OR of length\n     * other than 8 bytes is considered invalid (empty string in OTLP/JSON\n     * is zero-length and thus is also invalid).\n     *\n     * This field is optional. If the sender specifies a valid span_id then it SHOULD also\n     * specify a valid trace_id.\n     *\n     * The receivers SHOULD assume that the log record is not associated with a\n     * span if any of the following is true:\n     *   - the field is not present,\n     *   - the field contains an invalid value.\n     *\n     * @generated from protobuf field: bytes span_id = 10;\n     */\n    spanId: Uint8Array;\n}\n\n/**\n * @generated MessageType for protobuf message opentelemetry.proto.logs.v1.LogRecord\n */\nexport  const LogRecord: LogRecord$Type;\n\n/**\n * LogRecordFlags represents constants used to interpret the\n * LogRecord.flags field, which is protobuf 'fixed32' type and is to\n * be used as bit-fields. Each non-zero value defined in this enum is\n * a bit-mask.  To extract the bit-field, for example, use an\n * expression like:\n *\n *   (logRecord.flags \u0026 LOG_RECORD_FLAGS_TRACE_FLAGS_MASK)\n *\n *\n * @generated from protobuf enum opentelemetry.proto.logs.v1.LogRecordFlags\n */\nexport  enum LogRecordFlags {\n    /**\n     * The zero value for the enum. Should not be used for comparisons.\n     * Instead use bitwise \"and\" with the appropriate mask as shown above.\n     *\n     * @generated from protobuf enum value: LOG_RECORD_FLAGS_DO_NOT_USE = 0;\n     */\n    DO_NOT_USE = 0,\n    /**\n     * Bits 0-7 are used for trace flags.\n     *\n     * @generated from protobuf enum value: LOG_RECORD_FLAGS_TRACE_FLAGS_MASK = 255;\n     */\n    TRACE_FLAGS_MASK = 255\n}\n\nexport  class Logs extends Config {\n    constructor();\n}\n\nexport class LogsData$Type extends MessageType\u003cLogsData\u003e {\n    constructor();\n    create(value?: PartialMessage\u003cLogsData\u003e): LogsData;\n    internalBinaryRead(reader: IBinaryReader, length: number, options: BinaryReadOptions, target?: LogsData): LogsData;\n    internalBinaryWrite(message: LogsData, writer: IBinaryWriter, options: BinaryWriteOptions): IBinaryWriter;\n}\n\n/**\n * LogsData represents the logs data that can be stored in a persistent storage,\n * OR can be embedded by other protocols that transfer OTLP logs data but do not\n * implement the OTLP protocol.\n *\n * The main difference between this message and collector protocol is that\n * in this message there will not be any \"control\" or \"metadata\" specific to\n * OTLP protocol.\n *\n * When new fields are added into this message, the OTLP request MUST be updated\n * as well.\n *\n * @generated from protobuf message opentelemetry.proto.logs.v1.LogsData\n */\nexport  interface LogsData {\n    /**\n     * An array of ResourceLogs.\n     * For data coming from a single resource this array will typically contain\n     * one element. Intermediary nodes that receive data from multiple origins\n     * typically batch the data before forwarding further and in that case this\n     * array will contain multiple elements.\n     *\n     * @generated from protobuf field: repeated opentelemetry.proto.logs.v1.ResourceLogs resource_logs = 1;\n     */\n    resourceLogs: ResourceLogs[];\n}\n\n/**\n * @generated MessageType for protobuf message opentelemetry.proto.logs.v1.LogsData\n */\nexport  const LogsData: LogsData$Type;\n\n/**\n * JavaScript representation of 64 bit integral types. Equivalent to the\n * field option \"jstype\".\n *\n * By default, protobuf-ts represents 64 bit types as `bigint`.\n *\n * You can change the default behaviour by enabling the plugin parameter\n * `long_type_string`, which will represent 64 bit types as `string`.\n *\n * Alternatively, you can change the behaviour for individual fields\n * with the field option \"jstype\":\n *\n * ```protobuf\n * uint64 my_field = 1 [jstype = JS_STRING];\n * uint64 other_field = 2 [jstype = JS_NUMBER];\n * ```\n */\nexport enum LongType {\n    /**\n     * Use JavaScript `bigint`.\n     *\n     * Field option `[jstype = JS_NORMAL]`.\n     */\n    BIGINT = 0,\n    /**\n     * Use JavaScript `string`.\n     *\n     * Field option `[jstype = JS_STRING]`.\n     */\n    STRING = 1,\n    /**\n     * Use JavaScript `number`.\n     *\n     * Large values will loose precision.\n     *\n     * Field option `[jstype = JS_NUMBER]`.\n     */\n    NUMBER = 2\n}\n\n/**\n * Describes a protobuf message for runtime reflection.\n */\nexport interface MessageInfo {\n    /**\n     * The protobuf type name of the message, including package and\n     * parent types if present.\n     *\n     * If the .proto file included a `package` statement, the type name\n     * starts with '.'.\n     *\n     * Examples:\n     * 'MyNamespaceLessMessage'\n     * '.my_package.MyMessage'\n     * '.my_package.ParentMessage.ChildMessage'\n     */\n    readonly typeName: string;\n    /**\n     * Simple information for each message field, in the order\n     * of declaration in the source .proto.\n     */\n    readonly fields: readonly FieldInfo[];\n    /**\n     * Contains custom message options from the .proto source in JSON format.\n     */\n    readonly options: {\n        [extensionName: string]: JsonValue;\n    };\n}\n\n/**\n * This standard message type provides reflection-based\n * operations to work with a message.\n */\nexport class MessageType\u003cT extends object\u003e implements IMessageType\u003cT\u003e {\n    /**\n     * The protobuf type name of the message, including package and\n     * parent types if present.\n     *\n     * If the .proto file included a `package` statement,\n     * the type name will always start with a '.'.\n     *\n     * Examples:\n     * 'MyNamespaceLessMessage'\n     * '.my_package.MyMessage'\n     * '.my_package.ParentMessage.ChildMessage'\n     */\n    readonly typeName: string;\n    /**\n     * Simple information for each message field, in the order\n     * of declaration in the .proto.\n     */\n    readonly fields: readonly FieldInfo[];\n    /**\n     * Contains custom service options from the .proto source in JSON format.\n     */\n    readonly options: JsonOptionsMap;\n    /**\n     * Contains the prototype for messages returned by create() which\n     * includes the `MESSAGE_TYPE` symbol pointing back to `this`.\n     */\n    readonly messagePrototype?: Readonly\u003c{}\u003e | undefined;\n    protected readonly defaultCheckDepth = 16;\n    protected readonly refTypeCheck: ReflectionTypeCheck;\n    protected readonly refJsonReader: ReflectionJsonReader;\n    protected readonly refJsonWriter: ReflectionJsonWriter;\n    protected readonly refBinReader: ReflectionBinaryReader;\n    protected readonly refBinWriter: ReflectionBinaryWriter;\n    constructor(name: string, fields: readonly PartialFieldInfo[], options?: JsonOptionsMap);\n    /**\n     * Create a new message with default values.\n     *\n     * For example, a protobuf `string name = 1;` has the default value `\"\"`.\n     */\n    create(): T;\n    /**\n     * Create a new message from partial data.\n     * Where a field is omitted, the default value is used.\n     *\n     * Unknown fields are discarded.\n     *\n     * `PartialMessage\u003cT\u003e` is similar to `Partial\u003cT\u003e`,\n     * but it is recursive, and it keeps `oneof` groups\n     * intact.\n     */\n    create(value: PartialMessage\u003cT\u003e): T;\n    /**\n     * Clone the message.\n     *\n     * Unknown fields are discarded.\n     */\n    clone(message: T): T;\n    /**\n     * Determines whether two message of the same type have the same field values.\n     * Checks for deep equality, traversing repeated fields, oneof groups, maps\n     * and messages recursively.\n     * Will also return true if both messages are `undefined`.\n     */\n    equals(a: T | undefined, b: T | undefined): boolean;\n    /**\n     * Is the given value assignable to our message type\n     * and contains no [excess properties](https://www.typescriptlang.org/docs/handbook/interfaces.html#excess-property-checks)?\n     */\n    is(arg: any, depth?: number): arg is T;\n    /**\n     * Is the given value assignable to our message type,\n     * regardless of [excess properties](https://www.typescriptlang.org/docs/handbook/interfaces.html#excess-property-checks)?\n     */\n    isAssignable(arg: any, depth?: number): arg is T;\n    /**\n     * Copy partial data into the target message.\n     */\n    mergePartial(target: T, source: PartialMessage\u003cT\u003e): void;\n    /**\n     * Create a new message from binary format.\n     */\n    fromBinary(data: Uint8Array, options?: Partial\u003cBinaryReadOptions\u003e): T;\n    /**\n     * Read a new message from a JSON value.\n     */\n    fromJson(json: JsonValue, options?: Partial\u003cJsonReadOptions\u003e): T;\n    /**\n     * Read a new message from a JSON string.\n     * This is equivalent to `T.fromJson(JSON.parse(json))`.\n     */\n    fromJsonString(json: string, options?: Partial\u003cJsonReadOptions\u003e): T;\n    /**\n     * Write the message to canonical JSON value.\n     */\n    toJson(message: T, options?: Partial\u003cJsonWriteOptions\u003e): JsonValue;\n    /**\n     * Convert the message to canonical JSON string.\n     * This is equivalent to `JSON.stringify(T.toJson(t))`\n     */\n    toJsonString(message: T, options?: Partial\u003cJsonWriteStringOptions\u003e): string;\n    /**\n     * Write the message to binary format.\n     */\n    toBinary(message: T, options?: Partial\u003cBinaryWriteOptions\u003e): Uint8Array;\n    /**\n     * This is an internal method. If you just want to read a message from\n     * JSON, use `fromJson()` or `fromJsonString()`.\n     *\n     * Reads JSON value and merges the fields into the target\n     * according to protobuf rules. If the target is omitted,\n     * a new instance is created first.\n     */\n    internalJsonRead(json: JsonValue, options: JsonReadOptions, target?: T): T;\n    /**\n     * This is an internal method. If you just want to write a message\n     * to JSON, use `toJson()` or `toJsonString().\n     *\n     * Writes JSON value and returns it.\n     */\n    internalJsonWrite(message: T, options: JsonWriteOptions): JsonValue;\n    /**\n     * This is an internal method. If you just want to write a message\n     * in binary format, use `toBinary()`.\n     *\n     * Serializes the message in binary format and appends it to the given\n     * writer. Returns passed writer.\n     */\n    internalBinaryWrite(message: T, writer: IBinaryWriter, options: BinaryWriteOptions): IBinaryWriter;\n    /**\n     * This is an internal method. If you just want to read a message from\n     * binary data, use `fromBinary()`.\n     *\n     * Reads data from binary format and merges the fields into\n     * the target according to protobuf rules. If the target is\n     * omitted, a new instance is created first.\n     */\n    internalBinaryRead(reader: IBinaryReader, length: number, options: BinaryReadOptions, target?: T): T;\n}\n\nexport class Metric$Type extends MessageType\u003cMetric\u003e {\n    constructor();\n    create(value?: PartialMessage\u003cMetric\u003e): Metric;\n    internalBinaryRead(reader: IBinaryReader, length: number, options: BinaryReadOptions, target?: Metric): Metric;\n    internalBinaryWrite(message: Metric, writer: IBinaryWriter, options: BinaryWriteOptions): IBinaryWriter;\n}\n\n/**\n * Defines a Metric which has one or more timeseries.  The following is a\n * brief summary of the Metric data model.  For more details, see:\n *\n *   https://github.com/open-telemetry/opentelemetry-specification/blob/main/specification/metrics/data-model.md\n *\n *\n * The data model and relation between entities is shown in the\n * diagram below. Here, \"DataPoint\" is the term used to refer to any\n * one of the specific data point value types, and \"points\" is the term used\n * to refer to any one of the lists of points contained in the Metric.\n *\n * - Metric is composed of a metadata and data.\n * - Metadata part contains a name, description, unit.\n * - Data is one of the possible types (Sum, Gauge, Histogram, Summary).\n * - DataPoint contains timestamps, attributes, and one of the possible value type\n *   fields.\n *\n *     Metric\n *  +------------+\n *  |name        |\n *  |description |\n *  |unit        |     +------------------------------------+\n *  |data        |---\u003e |Gauge, Sum, Histogram, Summary, ... |\n *  +------------+     +------------------------------------+\n *\n *    Data [One of Gauge, Sum, Histogram, Summary, ...]\n *  +-----------+\n *  |...        |  // Metadata about the Data.\n *  |points     |--+\n *  +-----------+  |\n *                 |      +---------------------------+\n *                 |      |DataPoint 1                |\n *                 v      |+------+------+   +------+ |\n *              +-----+   ||label |label |...|label | |\n *              |  1  |--\u003e||value1|value2|...|valueN| |\n *              +-----+   |+------+------+   +------+ |\n *              |  .  |   |+-----+                    |\n *              |  .  |   ||value|                    |\n *              |  .  |   |+-----+                    |\n *              |  .  |   +---------------------------+\n *              |  .  |                   .\n *              |  .  |                   .\n *              |  .  |                   .\n *              |  .  |   +---------------------------+\n *              |  .  |   |DataPoint M                |\n *              +-----+   |+------+------+   +------+ |\n *              |  M  |--\u003e||label |label |...|label | |\n *              +-----+   ||value1|value2|...|valueN| |\n *                        |+------+------+   +------+ |\n *                        |+-----+                    |\n *                        ||value|                    |\n *                        |+-----+                    |\n *                        +---------------------------+\n *\n * Each distinct type of DataPoint represents the output of a specific\n * aggregation function, the result of applying the DataPoint's\n * associated function of to one or more measurements.\n *\n * All DataPoint types have three common fields:\n * - Attributes includes key-value pairs associated with the data point\n * - TimeUnixNano is required, set to the end time of the aggregation\n * - StartTimeUnixNano is optional, but strongly encouraged for DataPoints\n *   having an AggregationTemporality field, as discussed below.\n *\n * Both TimeUnixNano and StartTimeUnixNano values are expressed as\n * UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January 1970.\n *\n * # TimeUnixNano\n *\n * This field is required, having consistent interpretation across\n * DataPoint types.  TimeUnixNano is the moment corresponding to when\n * the data point's aggregate value was captured.\n *\n * Data points with the 0 value for TimeUnixNano SHOULD be rejected\n * by consumers.\n *\n * # StartTimeUnixNano\n *\n * StartTimeUnixNano in general allows detecting when a sequence of\n * observations is unbroken.  This field indicates to consumers the\n * start time for points with cumulative and delta\n * AggregationTemporality, and it should be included whenever possible\n * to support correct rate calculation.  Although it may be omitted\n * when the start time is truly unknown, setting StartTimeUnixNano is\n * strongly encouraged.\n *\n * @generated from protobuf message opentelemetry.proto.metrics.v1.Metric\n */\nexport  interface Metric {\n    /**\n     * name of the metric.\n     *\n     * @generated from protobuf field: string name = 1;\n     */\n    name: string;\n    /**\n     * description of the metric, which can be used in documentation.\n     *\n     * @generated from protobuf field: string description = 2;\n     */\n    description: string;\n    /**\n     * unit in which the metric value is reported. Follows the format\n     * described by http://unitsofmeasure.org/ucum.html.\n     *\n     * @generated from protobuf field: string unit = 3;\n     */\n    unit: string;\n    /**\n     * @generated from protobuf oneof: data\n     */\n    data: {\n        oneofKind: \"gauge\";\n        /**\n         * @generated from protobuf field: opentelemetry.proto.metrics.v1.Gauge gauge = 5;\n         */\n        gauge: Gauge;\n    } | {\n        oneofKind: \"sum\";\n        /**\n         * @generated from protobuf field: opentelemetry.proto.metrics.v1.Sum sum = 7;\n         */\n        sum: Sum;\n    } | {\n        oneofKind: \"histogram\";\n        /**\n         * @generated from protobuf field: opentelemetry.proto.metrics.v1.Histogram histogram = 9;\n         */\n        histogram: Histogram;\n    } | {\n        oneofKind: \"exponentialHistogram\";\n        /**\n         * @generated from protobuf field: opentelemetry.proto.metrics.v1.ExponentialHistogram exponential_histogram = 10;\n         */\n        exponentialHistogram: ExponentialHistogram;\n    } | {\n        oneofKind: \"summary\";\n        /**\n         * @generated from protobuf field: opentelemetry.proto.metrics.v1.Summary summary = 11;\n         */\n        summary: Summary;\n    } | {\n        oneofKind: undefined;\n    };\n    /**\n     * Additional metadata attributes that describe the metric. [Optional].\n     * Attributes are non-identifying.\n     * Consumers SHOULD NOT need to be aware of these attributes.\n     * These attributes MAY be used to encode information allowing\n     * for lossless roundtrip translation to / from another data model.\n     * Attribute keys MUST be unique (it is not allowed to have more than one\n     * attribute with the same key).\n     *\n     * @generated from protobuf field: repeated opentelemetry.proto.common.v1.KeyValue metadata = 12;\n     */\n    metadata: KeyValue[];\n}\n\n/**\n * @generated MessageType for protobuf message opentelemetry.proto.metrics.v1.Metric\n */\nexport  const Metric: Metric$Type;\n\nexport  class Metrics extends Config {\n    constructor(name?: string);\n    query(): ScanData;\n}\n\nexport class MetricsData$Type extends MessageType\u003cMetricsData\u003e {\n    constructor();\n    create(value?: PartialMessage\u003cMetricsData\u003e): MetricsData;\n    internalBinaryRead(reader: IBinaryReader, length: number, options: BinaryReadOptions, target?: MetricsData): MetricsData;\n    internalBinaryWrite(message: MetricsData, writer: IBinaryWriter, options: BinaryWriteOptions): IBinaryWriter;\n}\n\n/**\n * MetricsData represents the metrics data that can be stored in a persistent\n * storage, OR can be embedded by other protocols that transfer OTLP metrics\n * data but do not implement the OTLP protocol.\n *\n * The main difference between this message and collector protocol is that\n * in this message there will not be any \"control\" or \"metadata\" specific to\n * OTLP protocol.\n *\n * When new fields are added into this message, the OTLP request MUST be updated\n * as well.\n *\n * @generated from protobuf message opentelemetry.proto.metrics.v1.MetricsData\n */\nexport  interface MetricsData {\n    /**\n     * An array of ResourceMetrics.\n     * For data coming from a single resource this array will typically contain\n     * one element. Intermediary nodes that receive data from multiple origins\n     * typically batch the data before forwarding further and in that case this\n     * array will contain multiple elements.\n     *\n     * @generated from protobuf field: repeated opentelemetry.proto.metrics.v1.ResourceMetrics resource_metrics = 1;\n     */\n    resourceMetrics: ResourceMetrics[];\n}\n\n/**\n * @generated MessageType for protobuf message opentelemetry.proto.metrics.v1.MetricsData\n */\nexport  const MetricsData: MetricsData$Type;\n\n/**\n * `NullValue` is a singleton enumeration to represent the null value for the\n * `Value` type union.\n *\n *  The JSON representation for `NullValue` is JSON `null`.\n *\n * @generated from protobuf enum google.protobuf.NullValue\n */\nexport enum NullValue {\n    /**\n     * Null value.\n     *\n     * @generated from protobuf enum value: NULL_VALUE = 0;\n     */\n    NULL_VALUE = 0\n}\n\nexport class NumberDataPoint$Type extends MessageType\u003cNumberDataPoint\u003e {\n    constructor();\n    create(value?: PartialMessage\u003cNumberDataPoint\u003e): NumberDataPoint;\n    internalBinaryRead(reader: IBinaryReader, length: number, options: BinaryReadOptions, target?: NumberDataPoint): NumberDataPoint;\n    internalBinaryWrite(message: NumberDataPoint, writer: IBinaryWriter, options: BinaryWriteOptions): IBinaryWriter;\n}\n\n/**\n * NumberDataPoint is a single data point in a timeseries that describes the\n * time-varying scalar value of a metric.\n *\n * @generated from protobuf message opentelemetry.proto.metrics.v1.NumberDataPoint\n */\nexport  interface NumberDataPoint {\n    /**\n     * The set of key/value pairs that uniquely identify the timeseries from\n     * where this point belongs. The list may be empty (may contain 0 elements).\n     * Attribute keys MUST be unique (it is not allowed to have more than one\n     * attribute with the same key).\n     *\n     * @generated from protobuf field: repeated opentelemetry.proto.common.v1.KeyValue attributes = 7;\n     */\n    attributes: KeyValue[];\n    /**\n     * StartTimeUnixNano is optional but strongly encouraged, see the\n     * the detailed comments above Metric.\n     *\n     * Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January\n     * 1970.\n     *\n     * @generated from protobuf field: fixed64 start_time_unix_nano = 2;\n     */\n    startTimeUnixNano: number;\n    /**\n     * TimeUnixNano is required, see the detailed comments above Metric.\n     *\n     * Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January\n     * 1970.\n     *\n     * @generated from protobuf field: fixed64 time_unix_nano = 3;\n     */\n    timeUnixNano: number;\n    /**\n     * @generated from protobuf oneof: value\n     */\n    value: {\n        oneofKind: \"asDouble\";\n        /**\n         * @generated from protobuf field: double as_double = 4;\n         */\n        asDouble: number;\n    } | {\n        oneofKind: \"asInt\";\n        /**\n         * @generated from protobuf field: sfixed64 as_int = 6;\n         */\n        asInt: number;\n    } | {\n        oneofKind: undefined;\n    };\n    /**\n     * (Optional) List of exemplars collected from\n     * measurements that were used to form the data point\n     *\n     * @generated from protobuf field: repeated opentelemetry.proto.metrics.v1.Exemplar exemplars = 5;\n     */\n    exemplars: Exemplar[];\n    /**\n     * Flags that apply to this specific data point.  See DataPointFlags\n     * for the available flags and their meaning.\n     *\n     * @generated from protobuf field: uint32 flags = 8;\n     */\n    flags: number;\n}\n\n/**\n * @generated MessageType for protobuf message opentelemetry.proto.metrics.v1.NumberDataPoint\n */\nexport  const NumberDataPoint: NumberDataPoint$Type;\n\nexport type PartialField\u003cT\u003e = T extends (Date | Uint8Array | bigint | boolean | string | number) ? T : T extends Array\u003cinfer U\u003e ? Array\u003cPartialField\u003cU\u003e\u003e : T extends ReadonlyArray\u003cinfer U\u003e ? ReadonlyArray\u003cPartialField\u003cU\u003e\u003e : T extends {\n    oneofKind: string;\n} ? T : T extends {\n    oneofKind: undefined;\n} ? T : T extends object ? PartialMessage\u003cT\u003e : T;\n\n/**\n * Version of `FieldInfo` that allows the following properties\n * to be omitted:\n * - \"localName\", \"jsonName\": can be omitted if equal to lowerCamelCase(name)\n * - \"opt\": can be omitted if false\n * - \"repeat\", can be omitted if RepeatType.NO\n *\n * Use `normalizeFieldInfo()` to fill the omitted fields with\n * their standard values.\n */\nexport type PartialFieldInfo = fiPartialRules\u003cfiScalar\u003e | fiPartialRules\u003cfiEnum\u003e | fiPartialRules\u003cfiMessage\u003e | fiPartialRules\u003cfiMap\u003e;\n\n/**\n * Similar to `Partial\u003cT\u003e`, but recursive, and keeps `oneof` groups\n * intact.\n */\nexport type PartialMessage\u003cT extends object\u003e = {\n    [K in keyof T]?: PartialField\u003cT[K]\u003e;\n};\n\n/**\n * Version of `MessageInfo` that allows the following properties\n * to be omitted:\n * - \"fields\": omitting means the message has no fields\n * - \"options\": omitting means the message has no options\n */\nexport type PartialMessageInfo = PartialPartial\u003cMessageInfo, \"fields\" | \"options\"\u003e;\n\nexport type PartialPartial\u003cT, K extends keyof T\u003e = Partial\u003cPick\u003cT, K\u003e\u003e \u0026 Omit\u003cT, K\u003e;\n\n/**\n * 64-bit signed integer as two 32-bit values.\n * Converts between `string`, `number` and `bigint` representations.\n */\nexport class PbLong extends SharedPbLong {\n    /**\n     * long 0 singleton.\n     */\n    static ZERO: PbLong;\n    /**\n     * Create instance from a `string`, `number` or `bigint`.\n     */\n    static from(value: string | number | bigint): PbLong;\n    /**\n     * Do we have a minus sign?\n     */\n    isNegative(): boolean;\n    /**\n     * Negate two's complement.\n     * Invert all the bits and add one to the result.\n     */\n    negate(): PbLong;\n    /**\n     * Convert to decimal string.\n     */\n    toString(): string;\n    /**\n     * Convert to native bigint.\n     */\n    toBigInt(): bigint;\n}\n\n/**\n * 64-bit unsigned integer as two 32-bit values.\n * Converts between `string`, `number` and `bigint` representations.\n */\nexport class PbULong extends SharedPbLong {\n    /**\n     * ulong 0 singleton.\n     */\n    static ZERO: PbULong;\n    /**\n     * Create instance from a `string`, `number` or `bigint`.\n     */\n    static from(value: string | number | bigint): PbULong;\n    /**\n     * Convert to decimal string.\n     */\n    toString(): string;\n    /**\n     * Convert to native bigint.\n     */\n    toBigInt(): bigint;\n}\n\n/**\n * Reads proto3 messages in binary format using reflection information.\n *\n * https://developers.google.com/protocol-buffers/docs/encoding\n */\nexport class ReflectionBinaryReader {\n    private readonly info;\n    protected fieldNoToField?: ReadonlyMap\u003cnumber, FieldInfo\u003e;\n    constructor(info: PartialMessageInfo);\n    protected prepare(): void;\n    /**\n     * Reads a message from binary format into the target message.\n     *\n     * Repeated fields are appended. Map entries are added, overwriting\n     * existing keys.\n     *\n     * If a message field is already present, it will be merged with the\n     * new data.\n     */\n    read\u003cT extends object\u003e(reader: IBinaryReader, message: T, options: BinaryReadOptions, length?: number): void;\n    /**\n     * Read a map field, expecting key field = 1, value field = 2\n     */\n    protected mapEntry(field: FieldInfo \u0026 {\n        kind: \"map\";\n    }, reader: IBinaryReader, options: BinaryReadOptions): [string | number, UnknownMap[string]];\n    protected scalar(reader: IBinaryReader, type: ScalarType, longType: LongType | undefined): UnknownScalar;\n}\n\n/**\n * Writes proto3 messages in binary format using reflection information.\n *\n * https://developers.google.com/protocol-buffers/docs/encoding\n */\nexport class ReflectionBinaryWriter {\n    private readonly info;\n    protected fields?: readonly FieldInfo[];\n    constructor(info: PartialMessageInfo);\n    protected prepare(): void;\n    /**\n     * Writes the message to binary format.\n     */\n    write\u003cT extends object\u003e(message: T, writer: IBinaryWriter, options: BinaryWriteOptions): void;\n    protected mapEntry(writer: IBinaryWriter, options: BinaryWriteOptions, field: FieldInfo \u0026 {\n        kind: 'map';\n    }, key: any, value: any): void;\n    protected message(writer: IBinaryWriter, options: BinaryWriteOptions, handler: IMessageType\u003cany\u003e, fieldNo: number, value: any): void;\n    /**\n     * Write a single scalar value.\n     */\n    protected scalar(writer: IBinaryWriter, type: ScalarType, fieldNo: number, value: any, emitDefault: boolean): void;\n    /**\n     * Write an array of scalar values in packed format.\n     */\n    protected packed(writer: IBinaryWriter, type: ScalarType, fieldNo: number, value: any[]): void;\n    /**\n     * Get information for writing a scalar value.\n     *\n     * Returns tuple:\n     * [0]: appropriate WireType\n     * [1]: name of the appropriate method of IBinaryWriter\n     * [2]: whether the given value is a default value\n     *\n     * If argument `value` is omitted, [2] is always false.\n     */\n    protected scalarInfo(type: ScalarType, value?: any): [WireType, \"int32\" | \"string\" | \"bool\" | \"uint32\" | \"double\" | \"float\" | \"int64\" | \"uint64\" | \"fixed64\" | \"bytes\" | \"fixed32\" | \"sfixed32\" | \"sfixed64\" | \"sint32\" | \"sint64\", boolean];\n}\n\n/**\n * Reads proto3 messages in canonical JSON format using reflection information.\n *\n * https://developers.google.com/protocol-buffers/docs/proto3#json\n */\nexport class ReflectionJsonReader {\n    private readonly info;\n    /**\n     * JSON key to field.\n     * Accepts the original proto field name in the .proto, the\n     * lowerCamelCase name, or the name specified by the json_name option.\n     */\n    private fMap?;\n    constructor(info: PartialMessageInfo);\n    protected prepare(): void;\n    assert(condition: any, fieldName: string, jsonValue: JsonValue): asserts condition;\n    /**\n     * Reads a message from canonical JSON format into the target message.\n     *\n     * Repeated fields are appended. Map entries are added, overwriting\n     * existing keys.\n     *\n     * If a message field is already present, it will be merged with the\n     * new data.\n     */\n    read\u003cT extends object\u003e(input: JsonObject, message: T, options: JsonReadOptions): void;\n    /**\n     * Returns `false` for unrecognized string representations.\n     *\n     * google.protobuf.NullValue accepts only JSON `null` (or the old `\"NULL_VALUE\"`).\n     */\n    enum(type: EnumInfo, json: unknown, fieldName: string, ignoreUnknownFields: boolean): UnknownEnum | false;\n    scalar(json: JsonValue, type: ScalarType, longType: LongType | undefined, fieldName: string): UnknownScalar;\n}\n\n/**\n * Writes proto3 messages in canonical JSON format using reflection\n * information.\n *\n * https://developers.google.com/protocol-buffers/docs/proto3#json\n */\nexport class ReflectionJsonWriter {\n    private readonly fields;\n    constructor(info: PartialMessageInfo);\n    /**\n     * Converts the message to a JSON object, based on the field descriptors.\n     */\n    write\u003cT extends object\u003e(message: T, options: JsonWriteOptions): JsonValue;\n    field(field: FieldInfo, value: unknown, options: JsonWriteOptions): JsonValue | undefined;\n    /**\n     * Returns `null` as the default for google.protobuf.NullValue.\n     */\n    enum(type: EnumInfo, value: unknown, fieldName: string, optional: boolean, emitDefaultValues: boolean, enumAsInteger: boolean): JsonValue | undefined;\n    message(type: IMessageType\u003cany\u003e, value: unknown, fieldName: string, options: JsonWriteOptions): JsonValue | undefined;\n    scalar(type: ScalarType, value: unknown, fieldName: string, optional: false, emitDefaultValues: boolean): JsonValue;\n    scalar(type: ScalarType, value: unknown, fieldName: string, optional: boolean, emitDefaultValues: boolean): JsonValue | undefined;\n}\n\nexport class ReflectionTypeCheck {\n    private readonly fields;\n    private data;\n    constructor(info: PartialMessageInfo);\n    private prepare;\n    /**\n     * Is the argument a valid message as specified by the\n     * reflection information?\n     *\n     * Checks all field types recursively. The `depth`\n     * specifies how deep into the structure the check will be.\n     *\n     * With a depth of 0, only the presence of fields\n     * is checked.\n     *\n     * With a depth of 1 or more, the field types are checked.\n     *\n     * With a depth of 2 or more, the members of map, repeated\n     * and message fields are checked.\n     *\n     * Message fields will be checked recursively with depth - 1.\n     *\n     * The number of map entries / repeated values being checked\n     * is \u003c depth.\n     */\n    is(message: any, depth: number, allowExcessProperties?: boolean): boolean;\n    private field;\n    private message;\n    private messages;\n    private scalar;\n    private scalars;\n    private mapKeys;\n}\n\n/**\n * Serialize value and exit the script. This must only be called once, subsequent calls have\n * no effect.\n * @param value\n */\nexport  const render: (value: Struct | Data | ScanData) =\u003e void;\n\n/**\n * Protobuf 2.1.0 introduced packed repeated fields.\n * Setting the field option `[packed = true]` enables packing.\n *\n * In proto3, all repeated fields are packed by default.\n * Setting the field option `[packed = false]` disables packing.\n *\n * Packed repeated fields are encoded with a single tag,\n * then a length-delimiter, then the element values.\n *\n * Unpacked repeated fields are encoded with a tag and\n * value for each element.\n *\n * `bytes` and `string` cannot be packed.\n */\nexport enum RepeatType {\n    /**\n     * The field is not repeated.\n     */\n    NO = 0,\n    /**\n     * The field is repeated and should be packed.\n     * Invalid for `bytes` and `string`, they cannot be packed.\n     */\n    PACKED = 1,\n    /**\n     * The field is repeated but should not be packed.\n     * The only valid repeat type for repeated `bytes` and `string`.\n     */\n    UNPACKED = 2\n}\n\nexport class Resource$Type extends MessageType\u003cResource\u003e {\n    constructor();\n    create(value?: PartialMessage\u003cResource\u003e): Resource;\n    internalBinaryRead(reader: IBinaryReader, length: number, options: BinaryReadOptions, target?: Resource): Resource;\n    internalBinaryWrite(message: Resource, writer: IBinaryWriter, options: BinaryWriteOptions): IBinaryWriter;\n}\n\n/**\n * Resource information.\n *\n * @generated from protobuf message opentelemetry.proto.resource.v1.Resource\n */\nexport  interface Resource {\n    /**\n     * Set of attributes that describe the resource.\n     * Attribute keys MUST be unique (it is not allowed to have more than one\n     * attribute with the same key).\n     *\n     * @generated from protobuf field: repeated opentelemetry.proto.common.v1.KeyValue attributes = 1;\n     */\n    attributes: KeyValue[];\n    /**\n     * dropped_attributes_count is the number of dropped attributes. If the value is 0, then\n     * no attributes were dropped.\n     *\n     * @generated from protobuf field: uint32 dropped_attributes_count = 2;\n     */\n    droppedAttributesCount: number;\n}\n\n/**\n * @generated MessageType for protobuf message opentelemetry.proto.resource.v1.Resource\n */\nexport  const Resource: Resource$Type;\n\nexport class ResourceLogs$Type extends MessageType\u003cResourceLogs\u003e {\n    constructor();\n    create(value?: PartialMessage\u003cResourceLogs\u003e): ResourceLogs;\n    internalBinaryRead(reader: IBinaryReader, length: number, options: BinaryReadOptions, target?: ResourceLogs): ResourceLogs;\n    internalBinaryWrite(message: ResourceLogs, writer: IBinaryWriter, options: BinaryWriteOptions): IBinaryWriter;\n}\n\n/**\n * A collection of ScopeLogs from a Resource.\n *\n * @generated from protobuf message opentelemetry.proto.logs.v1.ResourceLogs\n */\nexport  interface ResourceLogs {\n    /**\n     * The resource for the logs in this message.\n     * If this field is not set then resource info is unknown.\n     *\n     * @generated from protobuf field: opentelemetry.proto.resource.v1.Resource resource = 1;\n     */\n    resource?: Resource;\n    /**\n     * A list of ScopeLogs that originate from a resource.\n     *\n     * @generated from protobuf field: repeated opentelemetry.proto.logs.v1.ScopeLogs scope_logs = 2;\n     */\n    scopeLogs: ScopeLogs[];\n    /**\n     * The Schema URL, if known. This is the identifier of the Schema that the resource data\n     * is recorded in. To learn more about Schema URL see\n     * https://opentelemetry.io/docs/specs/otel/schemas/#schema-url\n     * This schema_url applies to the data in the \"resource\" field. It does not apply\n     * to the data in the \"scope_logs\" field which have their own schema_url field.\n     *\n     * @generated from protobuf field: string schema_url = 3;\n     */\n    schemaUrl: string;\n}\n\n/**\n * @generated MessageType for protobuf message opentelemetry.proto.logs.v1.ResourceLogs\n */\nexport  const ResourceLogs: ResourceLogs$Type;\n\nexport class ResourceMetrics$Type extends MessageType\u003cResourceMetrics\u003e {\n    constructor();\n    create(value?: PartialMessage\u003cResourceMetrics\u003e): ResourceMetrics;\n    internalBinaryRead(reader: IBinaryReader, length: number, options: BinaryReadOptions, target?: ResourceMetrics): ResourceMetrics;\n    internalBinaryWrite(message: ResourceMetrics, writer: IBinaryWriter, options: BinaryWriteOptions): IBinaryWriter;\n}\n\n/**\n * A collection of ScopeMetrics from a Resource.\n *\n * @generated from protobuf message opentelemetry.proto.metrics.v1.ResourceMetrics\n */\nexport  interface ResourceMetrics {\n    /**\n     * The resource for the metrics in this message.\n     * If this field is not set then no resource info is known.\n     *\n     * @generated from protobuf field: opentelemetry.proto.resource.v1.Resource resource = 1;\n     */\n    resource?: Resource;\n    /**\n     * A list of metrics that originate from a resource.\n     *\n     * @generated from protobuf field: repeated opentelemetry.proto.metrics.v1.ScopeMetrics scope_metrics = 2;\n     */\n    scopeMetrics: ScopeMetrics[];\n    /**\n     * The Schema URL, if known. This is the identifier of the Schema that the resource data\n     * is recorded in. To learn more about Schema URL see\n     * https://opentelemetry.io/docs/specs/otel/schemas/#schema-url\n     * This schema_url applies to the data in the \"resource\" field. It does not apply\n     * to the data in the \"scope_metrics\" field which have their own schema_url field.\n     *\n     * @generated from protobuf field: string schema_url = 3;\n     */\n    schemaUrl: string;\n}\n\n/**\n * @generated MessageType for protobuf message opentelemetry.proto.metrics.v1.ResourceMetrics\n */\nexport  const ResourceMetrics: ResourceMetrics$Type;\n\nexport class ResourceSpans$Type extends MessageType\u003cResourceSpans\u003e {\n    constructor();\n    create(value?: PartialMessage\u003cResourceSpans\u003e): ResourceSpans;\n    internalBinaryRead(reader: IBinaryReader, length: number, options: BinaryReadOptions, target?: ResourceSpans): ResourceSpans;\n    internalBinaryWrite(message: ResourceSpans, writer: IBinaryWriter, options: BinaryWriteOptions): IBinaryWriter;\n}\n\n/**\n * A collection of ScopeSpans from a Resource.\n *\n * @generated from protobuf message opentelemetry.proto.trace.v1.ResourceSpans\n */\nexport  interface ResourceSpans {\n    /**\n     * The resource for the spans in this message.\n     * If this field is not set then no resource info is known.\n     *\n     * @generated from protobuf field: opentelemetry.proto.resource.v1.Resource resource = 1;\n     */\n    resource?: Resource;\n    /**\n     * A list of ScopeSpans that originate from a resource.\n     *\n     * @generated from protobuf field: repeated opentelemetry.proto.trace.v1.ScopeSpans scope_spans = 2;\n     */\n    scopeSpans: ScopeSpans[];\n    /**\n     * The Schema URL, if known. This is the identifier of the Schema that the resource data\n     * is recorded in. To learn more about Schema URL see\n     * https://opentelemetry.io/docs/specs/otel/schemas/#schema-url\n     * This schema_url applies to the data in the \"resource\" field. It does not apply\n     * to the data in the \"scope_spans\" field which have their own schema_url field.\n     *\n     * @generated from protobuf field: string schema_url = 3;\n     */\n    schemaUrl: string;\n}\n\n/**\n * @generated MessageType for protobuf message opentelemetry.proto.trace.v1.ResourceSpans\n */\nexport  const ResourceSpans: ResourceSpans$Type;\n\n/**\n * Scalar value types. This is a subset of field types declared by protobuf\n * enum google.protobuf.FieldDescriptorProto.Type The types GROUP and MESSAGE\n * are omitted, but the numerical values are identical.\n */\nexport enum ScalarType {\n    DOUBLE = 1,\n    FLOAT = 2,\n    INT64 = 3,\n    UINT64 = 4,\n    INT32 = 5,\n    FIXED64 = 6,\n    FIXED32 = 7,\n    BOOL = 8,\n    STRING = 9,\n    BYTES = 12,\n    UINT32 = 13,\n    SFIXED32 = 15,\n    SFIXED64 = 16,\n    SINT32 = 17,\n    SINT64 = 18\n}\n\nexport class Scan$Type extends MessageType\u003cScan\u003e {\n    constructor();\n}\n\n/**\n * @generated from protobuf message v1.Scan\n */\nexport  interface Scan {\n    /**\n     * @generated from protobuf field: v1.Scan.SCOPE scope = 1;\n     */\n    scope: Scan_SCOPE;\n    /**\n     * Timestamps to bound scan. This is optional, if it is not set a time range\n     * of the last 15 minutes since now.\n     *\n     * @generated from protobuf field: v1.Scan.TimeRange time_range = 2;\n     */\n    timeRange?: Scan_TimeRange;\n    /**\n     * @generated from protobuf field: repeated v1.Scan.Filter filters = 3;\n     */\n    filters: Scan_Filter[];\n    /**\n     * Number of samples to process. Defauluts to no limit.\n     *\n     * @generated from protobuf field: uint64 limit = 4;\n     */\n    limit: number;\n    /**\n     * Scans in reverse order, with latest samples comming first.  To get the\n     * latest sample you can set reverse to true and limit 1.\n     *\n     * @generated from protobuf field: bool reverse = 5;\n     */\n    reverse: boolean;\n    /**\n     * Now is current scan evaluation time. This is optional, when not set current\n     * system time is used.\n     *\n     * Useful for reprdocucible scanning by compining this with time_range a\n     * script can ensure it will be processing the same samples.\n     *\n     * @generated from protobuf field: google.protobuf.Timestamp now = 6;\n     */\n    now?: Timestamp;\n    /**\n     * Offset relative to current scanning time.\n     *\n     * @generated from protobuf field: google.protobuf.Duration offset = 7;\n     */\n    offset?: Duration;\n}\n\n/**\n * @generated MessageType for protobuf message v1.Scan\n */\nexport  const Scan: Scan$Type;\n\nexport class Scan_AttrFilter$Type extends MessageType\u003cScan_AttrFilter\u003e {\n    constructor();\n}\n\n/**\n * @generated from protobuf message v1.Scan.AttrFilter\n */\nexport  interface Scan_AttrFilter {\n    /**\n     * @generated from protobuf field: v1.Scan.AttributeProp prop = 1;\n     */\n    prop: Scan_AttributeProp;\n    /**\n     * @generated from protobuf field: string key = 2;\n     */\n    key: string;\n    /**\n     * @generated from protobuf field: string value = 3;\n     */\n    value: string;\n}\n\n/**\n * @generated MessageType for protobuf message v1.Scan.AttrFilter\n */\nexport  const Scan_AttrFilter: Scan_AttrFilter$Type;\n\n/**\n * @generated from protobuf enum v1.Scan.AttributeProp\n */\nexport  enum Scan_AttributeProp {\n    /**\n     * @generated from protobuf enum value: UNKOWN_ATTR = 0;\n     */\n    UNKOWN_ATTR = 0,\n    /**\n     * @generated from protobuf enum value: RESOURCE_ATTRIBUTES = 1;\n     */\n    RESOURCE_ATTRIBUTES = 1,\n    /**\n     * @generated from protobuf enum value: SCOPE_ATTRIBUTES = 5;\n     */\n    SCOPE_ATTRIBUTES = 5,\n    /**\n     * @generated from protobuf enum value: ATTRIBUTES = 7;\n     */\n    ATTRIBUTES = 7\n}\n\nexport class Scan_BaseFilter$Type extends MessageType\u003cScan_BaseFilter\u003e {\n    constructor();\n}\n\n/**\n * @generated from protobuf message v1.Scan.BaseFilter\n */\nexport  interface Scan_BaseFilter {\n    /**\n     * @generated from protobuf field: v1.Scan.BaseProp prop = 1;\n     */\n    prop: Scan_BaseProp;\n    /**\n     * @generated from protobuf field: string value = 2;\n     */\n    value: string;\n}\n\n/**\n * @generated MessageType for protobuf message v1.Scan.BaseFilter\n */\nexport  const Scan_BaseFilter: Scan_BaseFilter$Type;\n\n/**\n * @generated from protobuf enum v1.Scan.BaseProp\n */\nexport  enum Scan_BaseProp {\n    /**\n     * @generated from protobuf enum value: RESOURCE_SCHEMA = 0;\n     */\n    RESOURCE_SCHEMA = 0,\n    /**\n     * @generated from protobuf enum value: SCOPE_SCHEMA = 2;\n     */\n    SCOPE_SCHEMA = 2,\n    /**\n     * @generated from protobuf enum value: SCOPE_NAME = 3;\n     */\n    SCOPE_NAME = 3,\n    /**\n     * @generated from protobuf enum value: SCOPE_VERSION = 4;\n     */\n    SCOPE_VERSION = 4,\n    /**\n     * @generated from protobuf enum value: NAME = 6;\n     */\n    NAME = 6,\n    /**\n     * @generated from protobuf enum value: TRACE_ID = 8;\n     */\n    TRACE_ID = 8,\n    /**\n     * @generated from protobuf enum value: SPAN_ID = 9;\n     */\n    SPAN_ID = 9,\n    /**\n     * @generated from protobuf enum value: PARENT_SPAN_ID = 10;\n     */\n    PARENT_SPAN_ID = 10,\n    /**\n     * @generated from protobuf enum value: LOGS_LEVEL = 11;\n     */\n    LOGS_LEVEL = 11\n}\n\nexport class Scan_Filter$Type extends MessageType\u003cScan_Filter\u003e {\n    constructor();\n}\n\n/**\n * @generated from protobuf message v1.Scan.Filter\n */\nexport  interface Scan_Filter {\n    /**\n     * @generated from protobuf oneof: value\n     */\n    value: {\n        oneofKind: \"base\";\n        /**\n         * @generated from protobuf field: v1.Scan.BaseFilter base = 1;\n         */\n        base: Scan_BaseFilter;\n    } | {\n        oneofKind: \"attr\";\n        /**\n         * @generated from protobuf field: v1.Scan.AttrFilter attr = 2;\n         */\n        attr: Scan_AttrFilter;\n    } | {\n        oneofKind: undefined;\n    };\n}\n\n/**\n * @generated MessageType for protobuf message v1.Scan.Filter\n */\nexport  const Scan_Filter: Scan_Filter$Type;\n\n/**\n * @generated from protobuf enum v1.Scan.SCOPE\n */\nexport  enum Scan_SCOPE {\n    /**\n     * @generated from protobuf enum value: METRICS = 0;\n     */\n    METRICS = 0,\n    /**\n     * @generated from protobuf enum value: TRACES = 2;\n     */\n    TRACES = 2,\n    /**\n     * @generated from protobuf enum value: LOGS = 3;\n     */\n    LOGS = 3,\n    /**\n     * @generated from protobuf enum value: SNIPPETS = 4;\n     */\n    SNIPPETS = 4\n}\n\nexport class Scan_TimeRange$Type extends MessageType\u003cScan_TimeRange\u003e {\n    constructor();\n}\n\n/**\n * @generated from protobuf message v1.Scan.TimeRange\n */\nexport  interface Scan_TimeRange {\n    /**\n     * @generated from protobuf field: google.protobuf.Timestamp start = 1;\n     */\n    start?: Timestamp;\n    /**\n     * @generated from protobuf field: google.protobuf.Timestamp end = 2;\n     */\n    end?: Timestamp;\n}\n\n/**\n * @generated MessageType for protobuf message v1.Scan.TimeRange\n */\nexport  const Scan_TimeRange: Scan_TimeRange$Type;\n\nexport  class ScanData {\n    private ptr;\n    constructor(ptr: any);\n    toData(): Data;\n    formData(data: Data): ScanData;\n    static is(value: any): boolean;\n}\n\nexport class ScopeLogs$Type extends MessageType\u003cScopeLogs\u003e {\n    constructor();\n    create(value?: PartialMessage\u003cScopeLogs\u003e): ScopeLogs;\n    internalBinaryRead(reader: IBinaryReader, length: number, options: BinaryReadOptions, target?: ScopeLogs): ScopeLogs;\n    internalBinaryWrite(message: ScopeLogs, writer: IBinaryWriter, options: BinaryWriteOptions): IBinaryWriter;\n}\n\n/**\n * A collection of Logs produced by a Scope.\n *\n * @generated from protobuf message opentelemetry.proto.logs.v1.ScopeLogs\n */\nexport  interface ScopeLogs {\n    /**\n     * The instrumentation scope information for the logs in this message.\n     * Semantically when InstrumentationScope isn't set, it is equivalent with\n     * an empty instrumentation scope name (unknown).\n     *\n     * @generated from protobuf field: opentelemetry.proto.common.v1.InstrumentationScope scope = 1;\n     */\n    scope?: InstrumentationScope;\n    /**\n     * A list of log records.\n     *\n     * @generated from protobuf field: repeated opentelemetry.proto.logs.v1.LogRecord log_records = 2;\n     */\n    logRecords: LogRecord[];\n    /**\n     * The Schema URL, if known. This is the identifier of the Schema that the log data\n     * is recorded in. To learn more about Schema URL see\n     * https://opentelemetry.io/docs/specs/otel/schemas/#schema-url\n     * This schema_url applies to all logs in the \"logs\" field.\n     *\n     * @generated from protobuf field: string schema_url = 3;\n     */\n    schemaUrl: string;\n}\n\n/**\n * @generated MessageType for protobuf message opentelemetry.proto.logs.v1.ScopeLogs\n */\nexport  const ScopeLogs: ScopeLogs$Type;\n\nexport class ScopeMetrics$Type extends MessageType\u003cScopeMetrics\u003e {\n    constructor();\n    create(value?: PartialMessage\u003cScopeMetrics\u003e): ScopeMetrics;\n    internalBinaryRead(reader: IBinaryReader, length: number, options: BinaryReadOptions, target?: ScopeMetrics): ScopeMetrics;\n    internalBinaryWrite(message: ScopeMetrics, writer: IBinaryWriter, options: BinaryWriteOptions): IBinaryWriter;\n}\n\n/**\n * A collection of Metrics produced by an Scope.\n *\n * @generated from protobuf message opentelemetry.proto.metrics.v1.ScopeMetrics\n */\nexport  interface ScopeMetrics {\n    /**\n     * The instrumentation scope information for the metrics in this message.\n     * Semantically when InstrumentationScope isn't set, it is equivalent with\n     * an empty instrumentation scope name (unknown).\n     *\n     * @generated from protobuf field: opentelemetry.proto.common.v1.InstrumentationScope scope = 1;\n     */\n    scope?: InstrumentationScope;\n    /**\n     * A list of metrics that originate from an instrumentation library.\n     *\n     * @generated from protobuf field: repeated opentelemetry.proto.metrics.v1.Metric metrics = 2;\n     */\n    metrics: Metric[];\n    /**\n     * The Schema URL, if known. This is the identifier of the Schema that the metric data\n     * is recorded in. To learn more about Schema URL see\n     * https://opentelemetry.io/docs/specs/otel/schemas/#schema-url\n     * This schema_url applies to all metrics in the \"metrics\" field.\n     *\n     * @generated from protobuf field: string schema_url = 3;\n     */\n    schemaUrl: string;\n}\n\n/**\n * @generated MessageType for protobuf message opentelemetry.proto.metrics.v1.ScopeMetrics\n */\nexport  const ScopeMetrics: ScopeMetrics$Type;\n\nexport class ScopeSpans$Type extends MessageType\u003cScopeSpans\u003e {\n    constructor();\n    create(value?: PartialMessage\u003cScopeSpans\u003e): ScopeSpans;\n    internalBinaryRead(reader: IBinaryReader, length: number, options: BinaryReadOptions, target?: ScopeSpans): ScopeSpans;\n    internalBinaryWrite(message: ScopeSpans, writer: IBinaryWriter, options: BinaryWriteOptions): IBinaryWriter;\n}\n\n/**\n * A collection of Spans produced by an InstrumentationScope.\n *\n * @generated from protobuf message opentelemetry.proto.trace.v1.ScopeSpans\n */\nexport  interface ScopeSpans {\n    /**\n     * The instrumentation scope information for the spans in this message.\n     * Semantically when InstrumentationScope isn't set, it is equivalent with\n     * an empty instrumentation scope name (unknown).\n     *\n     * @generated from protobuf field: opentelemetry.proto.common.v1.InstrumentationScope scope = 1;\n     */\n    scope?: InstrumentationScope;\n    /**\n     * A list of Spans that originate from an instrumentation scope.\n     *\n     * @generated from protobuf field: repeated opentelemetry.proto.trace.v1.Span spans = 2;\n     */\n    spans: Span[];\n    /**\n     * The Schema URL, if known. This is the identifier of the Schema that the span data\n     * is recorded in. To learn more about Schema URL see\n     * https://opentelemetry.io/docs/specs/otel/schemas/#schema-url\n     * This schema_url applies to all spans and span events in the \"spans\" field.\n     *\n     * @generated from protobuf field: string schema_url = 3;\n     */\n    schemaUrl: string;\n}\n\n/**\n * @generated MessageType for protobuf message opentelemetry.proto.trace.v1.ScopeSpans\n */\nexport  const ScopeSpans: ScopeSpans$Type;\n\n/**\n * Possible values for LogRecord.SeverityNumber.\n *\n * @generated from protobuf enum opentelemetry.proto.logs.v1.SeverityNumber\n */\nexport  enum SeverityNumber {\n    /**\n     * UNSPECIFIED is the default SeverityNumber, it MUST NOT be used.\n     *\n     * @generated from protobuf enum value: SEVERITY_NUMBER_UNSPECIFIED = 0;\n     */\n    UNSPECIFIED = 0,\n    /**\n     * @generated from protobuf enum value: SEVERITY_NUMBER_TRACE = 1;\n     */\n    TRACE = 1,\n    /**\n     * @generated from protobuf enum value: SEVERITY_NUMBER_TRACE2 = 2;\n     */\n    TRACE2 = 2,\n    /**\n     * @generated from protobuf enum value: SEVERITY_NUMBER_TRACE3 = 3;\n     */\n    TRACE3 = 3,\n    /**\n     * @generated from protobuf enum value: SEVERITY_NUMBER_TRACE4 = 4;\n     */\n    TRACE4 = 4,\n    /**\n     * @generated from protobuf enum value: SEVERITY_NUMBER_DEBUG = 5;\n     */\n    DEBUG = 5,\n    /**\n     * @generated from protobuf enum value: SEVERITY_NUMBER_DEBUG2 = 6;\n     */\n    DEBUG2 = 6,\n    /**\n     * @generated from protobuf enum value: SEVERITY_NUMBER_DEBUG3 = 7;\n     */\n    DEBUG3 = 7,\n    /**\n     * @generated from protobuf enum value: SEVERITY_NUMBER_DEBUG4 = 8;\n     */\n    DEBUG4 = 8,\n    /**\n     * @generated from protobuf enum value: SEVERITY_NUMBER_INFO = 9;\n     */\n    INFO = 9,\n    /**\n     * @generated from protobuf enum value: SEVERITY_NUMBER_INFO2 = 10;\n     */\n    INFO2 = 10,\n    /**\n     * @generated from protobuf enum value: SEVERITY_NUMBER_INFO3 = 11;\n     */\n    INFO3 = 11,\n    /**\n     * @generated from protobuf enum value: SEVERITY_NUMBER_INFO4 = 12;\n     */\n    INFO4 = 12,\n    /**\n     * @generated from protobuf enum value: SEVERITY_NUMBER_WARN = 13;\n     */\n    WARN = 13,\n    /**\n     * @generated from protobuf enum value: SEVERITY_NUMBER_WARN2 = 14;\n     */\n    WARN2 = 14,\n    /**\n     * @generated from protobuf enum value: SEVERITY_NUMBER_WARN3 = 15;\n     */\n    WARN3 = 15,\n    /**\n     * @generated from protobuf enum value: SEVERITY_NUMBER_WARN4 = 16;\n     */\n    WARN4 = 16,\n    /**\n     * @generated from protobuf enum value: SEVERITY_NUMBER_ERROR = 17;\n     */\n    ERROR = 17,\n    /**\n     * @generated from protobuf enum value: SEVERITY_NUMBER_ERROR2 = 18;\n     */\n    ERROR2 = 18,\n    /**\n     * @generated from protobuf enum value: SEVERITY_NUMBER_ERROR3 = 19;\n     */\n    ERROR3 = 19,\n    /**\n     * @generated from protobuf enum value: SEVERITY_NUMBER_ERROR4 = 20;\n     */\n    ERROR4 = 20,\n    /**\n     * @generated from protobuf enum value: SEVERITY_NUMBER_FATAL = 21;\n     */\n    FATAL = 21,\n    /**\n     * @generated from protobuf enum value: SEVERITY_NUMBER_FATAL2 = 22;\n     */\n    FATAL2 = 22,\n    /**\n     * @generated from protobuf enum value: SEVERITY_NUMBER_FATAL3 = 23;\n     */\n    FATAL3 = 23,\n    /**\n     * @generated from protobuf enum value: SEVERITY_NUMBER_FATAL4 = 24;\n     */\n    FATAL4 = 24\n}\n\nexport abstract class SharedPbLong {\n    /**\n     * Low 32 bits.\n     */\n    readonly lo: number;\n    /**\n     * High 32 bits.\n     */\n    readonly hi: number;\n    /**\n     * Create a new instance with the given bits.\n     */\n    constructor(lo: number, hi: number);\n    /**\n     * Is this instance equal to 0?\n     */\n    isZero(): boolean;\n    /**\n     * Convert to a native number.\n     */\n    toNumber(): number;\n    /**\n     * Convert to decimal string.\n     */\n    abstract toString(): string;\n    /**\n     * Convert to native bigint.\n     */\n    abstract toBigInt(): bigint;\n}\n\nexport class Span$Type extends MessageType\u003cSpan\u003e {\n    constructor();\n    create(value?: PartialMessage\u003cSpan\u003e): Span;\n    internalBinaryRead(reader: IBinaryReader, length: number, options: BinaryReadOptions, target?: Span): Span;\n    internalBinaryWrite(message: Span, writer: IBinaryWriter, options: BinaryWriteOptions): IBinaryWriter;\n}\n\n/**\n * A Span represents a single operation performed by a single component of the system.\n *\n * The next available field id is 17.\n *\n * @generated from protobuf message opentelemetry.proto.trace.v1.Span\n */\nexport  interface Span {\n    /**\n     * A unique identifier for a trace. All spans from the same trace share\n     * the same `trace_id`. The ID is a 16-byte array. An ID with all zeroes OR\n     * of length other than 16 bytes is considered invalid (empty string in OTLP/JSON\n     * is zero-length and thus is also invalid).\n     *\n     * This field is required.\n     *\n     * @generated from protobuf field: bytes trace_id = 1;\n     */\n    traceId: Uint8Array;\n    /**\n     * A unique identifier for a span within a trace, assigned when the span\n     * is created. The ID is an 8-byte array. An ID with all zeroes OR of length\n     * other than 8 bytes is considered invalid (empty string in OTLP/JSON\n     * is zero-length and thus is also invalid).\n     *\n     * This field is required.\n     *\n     * @generated from protobuf field: bytes span_id = 2;\n     */\n    spanId: Uint8Array;\n    /**\n     * trace_state conveys information about request position in multiple distributed tracing graphs.\n     * It is a trace_state in w3c-trace-context format: https://www.w3.org/TR/trace-context/#tracestate-header\n     * See also https://github.com/w3c/distributed-tracing for more details about this field.\n     *\n     * @generated from protobuf field: string trace_state = 3;\n     */\n    traceState: string;\n    /**\n     * The `span_id` of this span's parent span. If this is a root span, then this\n     * field must be empty. The ID is an 8-byte array.\n     *\n     * @generated from protobuf field: bytes parent_span_id = 4;\n     */\n    parentSpanId: Uint8Array;\n    /**\n     * Flags, a bit field.\n     *\n     * Bits 0-7 (8 least significant bits) are the trace flags as defined in W3C Trace\n     * Context specification. To read the 8-bit W3C trace flag, use\n     * `flags \u0026 SPAN_FLAGS_TRACE_FLAGS_MASK`.\n     *\n     * See https://www.w3.org/TR/trace-context-2/#trace-flags for the flag definitions.\n     *\n     * Bits 8 and 9 represent the 3 states of whether a span's parent\n     * is remote. The states are (unknown, is not remote, is remote).\n     * To read whether the value is known, use `(flags \u0026 SPAN_FLAGS_CONTEXT_HAS_IS_REMOTE_MASK) != 0`.\n     * To read whether the span is remote, use `(flags \u0026 SPAN_FLAGS_CONTEXT_IS_REMOTE_MASK) != 0`.\n     *\n     * When creating span messages, if the message is logically forwarded from another source\n     * with an equivalent flags fields (i.e., usually another OTLP span message), the field SHOULD\n     * be copied as-is. If creating from a source that does not have an equivalent flags field\n     * (such as a runtime representation of an OpenTelemetry span), the high 22 bits MUST\n     * be set to zero.\n     * Readers MUST NOT assume that bits 10-31 (22 most significant bits) will be zero.\n     *\n     * [Optional].\n     *\n     * @generated from protobuf field: fixed32 flags = 16;\n     */\n    flags: number;\n    /**\n     * A description of the span's operation.\n     *\n     * For example, the name can be a qualified method name or a file name\n     * and a line number where the operation is called. A best practice is to use\n     * the same display name at the same call point in an application.\n     * This makes it easier to correlate spans in different traces.\n     *\n     * This field is semantically required to be set to non-empty string.\n     * Empty value is equivalent to an unknown span name.\n     *\n     * This field is required.\n     *\n     * @generated from protobuf field: string name = 5;\n     */\n    name: string;\n    /**\n     * Distinguishes between spans generated in a particular context. For example,\n     * two spans with the same name may be distinguished using `CLIENT` (caller)\n     * and `SERVER` (callee) to identify queueing latency associated with the span.\n     *\n     * @generated from protobuf field: opentelemetry.proto.trace.v1.Span.SpanKind kind = 6;\n     */\n    kind: Span_SpanKind;\n    /**\n     * start_time_unix_nano is the start time of the span. On the client side, this is the time\n     * kept by the local machine where the span execution starts. On the server side, this\n     * is the time when the server's application handler starts running.\n     * Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January 1970.\n     *\n     * This field is semantically required and it is expected that end_time \u003e= start_time.\n     *\n     * @generated from protobuf field: fixed64 start_time_unix_nano = 7;\n     */\n    startTimeUnixNano: number;\n    /**\n     * end_time_unix_nano is the end time of the span. On the client side, this is the time\n     * kept by the local machine where the span execution ends. On the server side, this\n     * is the time when the server application handler stops running.\n     * Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January 1970.\n     *\n     * This field is semantically required and it is expected that end_time \u003e= start_time.\n     *\n     * @generated from protobuf field: fixed64 end_time_unix_nano = 8;\n     */\n    endTimeUnixNano: number;\n    /**\n     * attributes is a collection of key/value pairs. Note, global attributes\n     * like server name can be set using the resource API. Examples of attributes:\n     *\n     *     \"/http/user_agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36\"\n     *     \"/http/server_latency\": 300\n     *     \"example.com/myattribute\": true\n     *     \"example.com/score\": 10.239\n     *\n     * The OpenTelemetry API specification further restricts the allowed value types:\n     * https://github.com/open-telemetry/opentelemetry-specification/blob/main/specification/common/README.md#attribute\n     * Attribute keys MUST be unique (it is not allowed to have more than one\n     * attribute with the same key).\n     *\n     * @generated from protobuf field: repeated opentelemetry.proto.common.v1.KeyValue attributes = 9;\n     */\n    attributes: KeyValue[];\n    /**\n     * dropped_attributes_count is the number of attributes that were discarded. Attributes\n     * can be discarded because their keys are too long or because there are too many\n     * attributes. If this value is 0, then no attributes were dropped.\n     *\n     * @generated from protobuf field: uint32 dropped_attributes_count = 10;\n     */\n    droppedAttributesCount: number;\n    /**\n     * events is a collection of Event items.\n     *\n     * @generated from protobuf field: repeated opentelemetry.proto.trace.v1.Span.Event events = 11;\n     */\n    events: Span_Event[];\n    /**\n     * dropped_events_count is the number of dropped events. If the value is 0, then no\n     * events were dropped.\n     *\n     * @generated from protobuf field: uint32 dropped_events_count = 12;\n     */\n    droppedEventsCount: number;\n    /**\n     * links is a collection of Links, which are references from this span to a span\n     * in the same or different trace.\n     *\n     * @generated from protobuf field: repeated opentelemetry.proto.trace.v1.Span.Link links = 13;\n     */\n    links: Span_Link[];\n    /**\n     * dropped_links_count is the number of dropped links after the maximum size was\n     * enforced. If this value is 0, then no links were dropped.\n     *\n     * @generated from protobuf field: uint32 dropped_links_count = 14;\n     */\n    droppedLinksCount: number;\n    /**\n     * An optional final status for this span. Semantically when Status isn't set, it means\n     * span's status code is unset, i.e. assume STATUS_CODE_UNSET (code = 0).\n     *\n     * @generated from protobuf field: opentelemetry.proto.trace.v1.Status status = 15;\n     */\n    status?: Status;\n}\n\n/**\n * @generated MessageType for protobuf message opentelemetry.proto.trace.v1.Span\n */\nexport  const Span: Span$Type;\n\nexport class Span_Event$Type extends MessageType\u003cSpan_Event\u003e {\n    constructor();\n    create(value?: PartialMessage\u003cSpan_Event\u003e): Span_Event;\n    internalBinaryRead(reader: IBinaryReader, length: number, options: BinaryReadOptions, target?: Span_Event): Span_Event;\n    internalBinaryWrite(message: Span_Event, writer: IBinaryWriter, options: BinaryWriteOptions): IBinaryWriter;\n}\n\n/**\n * Event is a time-stamped annotation of the span, consisting of user-supplied\n * text description and key-value pairs.\n *\n * @generated from protobuf message opentelemetry.proto.trace.v1.Span.Event\n */\nexport  interface Span_Event {\n    /**\n     * time_unix_nano is the time the event occurred.\n     *\n     * @generated from protobuf field: fixed64 time_unix_nano = 1;\n     */\n    timeUnixNano: number;\n    /**\n     * name of the event.\n     * This field is semantically required to be set to non-empty string.\n     *\n     * @generated from protobuf field: string name = 2;\n     */\n    name: string;\n    /**\n     * attributes is a collection of attribute key/value pairs on the event.\n     * Attribute keys MUST be unique (it is not allowed to have more than one\n     * attribute with the same key).\n     *\n     * @generated from protobuf field: repeated opentelemetry.proto.common.v1.KeyValue attributes = 3;\n     */\n    attributes: KeyValue[];\n    /**\n     * dropped_attributes_count is the number of dropped attributes. If the value is 0,\n     * then no attributes were dropped.\n     *\n     * @generated from protobuf field: uint32 dropped_attributes_count = 4;\n     */\n    droppedAttributesCount: number;\n}\n\n/**\n * @generated MessageType for protobuf message opentelemetry.proto.trace.v1.Span.Event\n */\nexport  const Span_Event: Span_Event$Type;\n\nexport class Span_Link$Type extends MessageType\u003cSpan_Link\u003e {\n    constructor();\n    create(value?: PartialMessage\u003cSpan_Link\u003e): Span_Link;\n    internalBinaryRead(reader: IBinaryReader, length: number, options: BinaryReadOptions, target?: Span_Link): Span_Link;\n    internalBinaryWrite(message: Span_Link, writer: IBinaryWriter, options: BinaryWriteOptions): IBinaryWriter;\n}\n\n/**\n * A pointer from the current span to another span in the same trace or in a\n * different trace. For example, this can be used in batching operations,\n * where a single batch handler processes multiple requests from different\n * traces or when the handler receives a request from a different project.\n *\n * @generated from protobuf message opentelemetry.proto.trace.v1.Span.Link\n */\nexport  interface Span_Link {\n    /**\n     * A unique identifier of a trace that this linked span is part of. The ID is a\n     * 16-byte array.\n     *\n     * @generated from protobuf field: bytes trace_id = 1;\n     */\n    traceId: Uint8Array;\n    /**\n     * A unique identifier for the linked span. The ID is an 8-byte array.\n     *\n     * @generated from protobuf field: bytes span_id = 2;\n     */\n    spanId: Uint8Array;\n    /**\n     * The trace_state associated with the link.\n     *\n     * @generated from protobuf field: string trace_state = 3;\n     */\n    traceState: string;\n    /**\n     * attributes is a collection of attribute key/value pairs on the link.\n     * Attribute keys MUST be unique (it is not allowed to have more than one\n     * attribute with the same key).\n     *\n     * @generated from protobuf field: repeated opentelemetry.proto.common.v1.KeyValue attributes = 4;\n     */\n    attributes: KeyValue[];\n    /**\n     * dropped_attributes_count is the number of dropped attributes. If the value is 0,\n     * then no attributes were dropped.\n     *\n     * @generated from protobuf field: uint32 dropped_attributes_count = 5;\n     */\n    droppedAttributesCount: number;\n    /**\n     * Flags, a bit field.\n     *\n     * Bits 0-7 (8 least significant bits) are the trace flags as defined in W3C Trace\n     * Context specification. To read the 8-bit W3C trace flag, use\n     * `flags \u0026 SPAN_FLAGS_TRACE_FLAGS_MASK`.\n     *\n     * See https://www.w3.org/TR/trace-context-2/#trace-flags for the flag definitions.\n     *\n     * Bits 8 and 9 represent the 3 states of whether the link is remote.\n     * The states are (unknown, is not remote, is remote).\n     * To read whether the value is known, use `(flags \u0026 SPAN_FLAGS_CONTEXT_HAS_IS_REMOTE_MASK) != 0`.\n     * To read whether the link is remote, use `(flags \u0026 SPAN_FLAGS_CONTEXT_IS_REMOTE_MASK) != 0`.\n     *\n     * Readers MUST NOT assume that bits 10-31 (22 most significant bits) will be zero.\n     * When creating new spans, bits 10-31 (most-significant 22-bits) MUST be zero.\n     *\n     * [Optional].\n     *\n     * @generated from protobuf field: fixed32 flags = 6;\n     */\n    flags: number;\n}\n\n/**\n * @generated MessageType for protobuf message opentelemetry.proto.trace.v1.Span.Link\n */\nexport  const Span_Link: Span_Link$Type;\n\n/**\n * SpanKind is the type of span. Can be used to specify additional relationships between spans\n * in addition to a parent/child relationship.\n *\n * @generated from protobuf enum opentelemetry.proto.trace.v1.Span.SpanKind\n */\nexport  enum Span_SpanKind {\n    /**\n     * Unspecified. Do NOT use as default.\n     * Implementations MAY assume SpanKind to be INTERNAL when receiving UNSPECIFIED.\n     *\n     * @generated from protobuf enum value: SPAN_KIND_UNSPECIFIED = 0;\n     */\n    UNSPECIFIED = 0,\n    /**\n     * Indicates that the span represents an internal operation within an application,\n     * as opposed to an operation happening at the boundaries. Default value.\n     *\n     * @generated from protobuf enum value: SPAN_KIND_INTERNAL = 1;\n     */\n    INTERNAL = 1,\n    /**\n     * Indicates that the span covers server-side handling of an RPC or other\n     * remote network request.\n     *\n     * @generated from protobuf enum value: SPAN_KIND_SERVER = 2;\n     */\n    SERVER = 2,\n    /**\n     * Indicates that the span describes a request to some remote service.\n     *\n     * @generated from protobuf enum value: SPAN_KIND_CLIENT = 3;\n     */\n    CLIENT = 3,\n    /**\n     * Indicates that the span describes a producer sending a message to a broker.\n     * Unlike CLIENT and SERVER, there is often no direct critical path latency relationship\n     * between producer and consumer spans. A PRODUCER span ends when the message was accepted\n     * by the broker while the logical processing of the message might span a much longer time.\n     *\n     * @generated from protobuf enum value: SPAN_KIND_PRODUCER = 4;\n     */\n    PRODUCER = 4,\n    /**\n     * Indicates that the span describes consumer receiving a message from a broker.\n     * Like the PRODUCER kind, there is often no direct critical path latency relationship\n     * between producer and consumer spans.\n     *\n     * @generated from protobuf enum value: SPAN_KIND_CONSUMER = 5;\n     */\n    CONSUMER = 5\n}\n\n/**\n * SpanFlags represents constants used to interpret the\n * Span.flags field, which is protobuf 'fixed32' type and is to\n * be used as bit-fields. Each non-zero value defined in this enum is\n * a bit-mask.  To extract the bit-field, for example, use an\n * expression like:\n *\n *   (span.flags \u0026 SPAN_FLAGS_TRACE_FLAGS_MASK)\n *\n * See https://www.w3.org/TR/trace-context-2/#trace-flags for the flag definitions.\n *\n * Note that Span flags were introduced in version 1.1 of the\n * OpenTelemetry protocol.  Older Span producers do not set this\n * field, consequently consumers should not rely on the absence of a\n * particular flag bit to indicate the presence of a particular feature.\n *\n * @generated from protobuf enum opentelemetry.proto.trace.v1.SpanFlags\n */\nexport  enum SpanFlags {\n    /**\n     * The zero value for the enum. Should not be used for comparisons.\n     * Instead use bitwise \"and\" with the appropriate mask as shown above.\n     *\n     * @generated from protobuf enum value: SPAN_FLAGS_DO_NOT_USE = 0;\n     */\n    DO_NOT_USE = 0,\n    /**\n     * Bits 0-7 are used for trace flags.\n     *\n     * @generated from protobuf enum value: SPAN_FLAGS_TRACE_FLAGS_MASK = 255;\n     */\n    TRACE_FLAGS_MASK = 255,\n    /**\n     * Bits 8 and 9 are used to indicate that the parent span or link span is remote.\n     * Bit 8 (`HAS_IS_REMOTE`) indicates whether the value is known.\n     * Bit 9 (`IS_REMOTE`) indicates whether the span or link is remote.\n     *\n     * @generated from protobuf enum value: SPAN_FLAGS_CONTEXT_HAS_IS_REMOTE_MASK = 256;\n     */\n    CONTEXT_HAS_IS_REMOTE_MASK = 256,\n    /**\n     * @generated from protobuf enum value: SPAN_FLAGS_CONTEXT_IS_REMOTE_MASK = 512;\n     */\n    CONTEXT_IS_REMOTE_MASK = 512\n}\n\nexport class Status$Type extends MessageType\u003cStatus\u003e {\n    constructor();\n    create(value?: PartialMessage\u003cStatus\u003e): Status;\n    internalBinaryRead(reader: IBinaryReader, length: number, options: BinaryReadOptions, target?: Status): Status;\n    internalBinaryWrite(message: Status, writer: IBinaryWriter, options: BinaryWriteOptions): IBinaryWriter;\n}\n\n/**\n * The Status type defines a logical error model that is suitable for different\n * programming environments, including REST APIs and RPC APIs.\n *\n * @generated from protobuf message opentelemetry.proto.trace.v1.Status\n */\nexport  interface Status {\n    /**\n     * A developer-facing human readable error message.\n     *\n     * @generated from protobuf field: string message = 2;\n     */\n    message: string;\n    /**\n     * The status code.\n     *\n     * @generated from protobuf field: opentelemetry.proto.trace.v1.Status.StatusCode code = 3;\n     */\n    code: Status_StatusCode;\n}\n\n/**\n * @generated MessageType for protobuf message opentelemetry.proto.trace.v1.Status\n */\nexport  const Status: Status$Type;\n\n/**\n * For the semantics of status codes see\n * https://github.com/open-telemetry/opentelemetry-specification/blob/main/specification/trace/api.md#set-status\n *\n * @generated from protobuf enum opentelemetry.proto.trace.v1.Status.StatusCode\n */\nexport  enum Status_StatusCode {\n    /**\n     * The default status.\n     *\n     * @generated from protobuf enum value: STATUS_CODE_UNSET = 0;\n     */\n    UNSET = 0,\n    /**\n     * The Span has been validated by an Application developer or Operator to\n     * have completed successfully.\n     *\n     * @generated from protobuf enum value: STATUS_CODE_OK = 1;\n     */\n    OK = 1,\n    /**\n     * The Span contains an error.\n     *\n     * @generated from protobuf enum value: STATUS_CODE_ERROR = 2;\n     */\n    ERROR = 2\n}\n\nexport class Struct$Type extends MessageType\u003cStruct\u003e {\n    constructor();\n    /**\n     * Encode `Struct` to JSON object.\n     */\n    internalJsonWrite(message: Struct, options: JsonWriteOptions): JsonValue;\n    /**\n     * Decode `Struct` from JSON object.\n     */\n    internalJsonRead(json: JsonValue, options: JsonReadOptions, target?: Struct): Struct;\n}\n\n/**\n * `Struct` represents a structured data value, consisting of fields\n * which map to dynamically typed values. In some languages, `Struct`\n * might be supported by a native representation. For example, in\n * scripting languages like JS a struct is represented as an\n * object. The details of that representation are described together\n * with the proto support for the language.\n *\n * The JSON representation for `Struct` is JSON object.\n *\n * @generated from protobuf message google.protobuf.Struct\n */\nexport interface Struct {\n    /**\n     * Unordered map of dynamically typed values.\n     *\n     * @generated from protobuf field: map\u003cstring, google.protobuf.Value\u003e fields = 1;\n     */\n    fields: {\n        [key: string]: Value;\n    };\n}\n\n/**\n * @generated MessageType for protobuf message google.protobuf.Struct\n */\nexport const Struct: Struct$Type;\n\nexport class Sum$Type extends MessageType\u003cSum\u003e {\n    constructor();\n    create(value?: PartialMessage\u003cSum\u003e): Sum;\n    internalBinaryRead(reader: IBinaryReader, length: number, options: BinaryReadOptions, target?: Sum): Sum;\n    internalBinaryWrite(message: Sum, writer: IBinaryWriter, options: BinaryWriteOptions): IBinaryWriter;\n}\n\n/**\n * Sum represents the type of a scalar metric that is calculated as a sum of all\n * reported measurements over a time interval.\n *\n * @generated from protobuf message opentelemetry.proto.metrics.v1.Sum\n */\nexport  interface Sum {\n    /**\n     * @generated from protobuf field: repeated opentelemetry.proto.metrics.v1.NumberDataPoint data_points = 1;\n     */\n    dataPoints: NumberDataPoint[];\n    /**\n     * aggregation_temporality describes if the aggregator reports delta changes\n     * since last report time, or cumulative changes since a fixed start time.\n     *\n     * @generated from protobuf field: opentelemetry.proto.metrics.v1.AggregationTemporality aggregation_temporality = 2;\n     */\n    aggregationTemporality: AggregationTemporality;\n    /**\n     * If \"true\" means that the sum is monotonic.\n     *\n     * @generated from protobuf field: bool is_monotonic = 3;\n     */\n    isMonotonic: boolean;\n}\n\n/**\n * @generated MessageType for protobuf message opentelemetry.proto.metrics.v1.Sum\n */\nexport  const Sum: Sum$Type;\n\nexport class Summary$Type extends MessageType\u003cSummary\u003e {\n    constructor();\n    create(value?: PartialMessage\u003cSummary\u003e): Summary;\n    internalBinaryRead(reader: IBinaryReader, length: number, options: BinaryReadOptions, target?: Summary): Summary;\n    internalBinaryWrite(message: Summary, writer: IBinaryWriter, options: BinaryWriteOptions): IBinaryWriter;\n}\n\n/**\n * Summary metric data are used to convey quantile summaries,\n * a Prometheus (see: https://prometheus.io/docs/concepts/metric_types/#summary)\n * and OpenMetrics (see: https://github.com/OpenObservability/OpenMetrics/blob/4dbf6075567ab43296eed941037c12951faafb92/protos/prometheus.proto#L45)\n * data type. These data points cannot always be merged in a meaningful way.\n * While they can be useful in some applications, histogram data points are\n * recommended for new applications.\n *\n * @generated from protobuf message opentelemetry.proto.metrics.v1.Summary\n */\nexport  interface Summary {\n    /**\n     * @generated from protobuf field: repeated opentelemetry.proto.metrics.v1.SummaryDataPoint data_points = 1;\n     */\n    dataPoints: SummaryDataPoint[];\n}\n\n/**\n * @generated MessageType for protobuf message opentelemetry.proto.metrics.v1.Summary\n */\nexport  const Summary: Summary$Type;\n\nexport class SummaryDataPoint$Type extends MessageType\u003cSummaryDataPoint\u003e {\n    constructor();\n    create(value?: PartialMessage\u003cSummaryDataPoint\u003e): SummaryDataPoint;\n    internalBinaryRead(reader: IBinaryReader, length: number, options: BinaryReadOptions, target?: SummaryDataPoint): SummaryDataPoint;\n    internalBinaryWrite(message: SummaryDataPoint, writer: IBinaryWriter, options: BinaryWriteOptions): IBinaryWriter;\n}\n\n/**\n * SummaryDataPoint is a single data point in a timeseries that describes the\n * time-varying values of a Summary metric.\n *\n * @generated from protobuf message opentelemetry.proto.metrics.v1.SummaryDataPoint\n */\nexport  interface SummaryDataPoint {\n    /**\n     * The set of key/value pairs that uniquely identify the timeseries from\n     * where this point belongs. The list may be empty (may contain 0 elements).\n     * Attribute keys MUST be unique (it is not allowed to have more than one\n     * attribute with the same key).\n     *\n     * @generated from protobuf field: repeated opentelemetry.proto.common.v1.KeyValue attributes = 7;\n     */\n    attributes: KeyValue[];\n    /**\n     * StartTimeUnixNano is optional but strongly encouraged, see the\n     * the detailed comments above Metric.\n     *\n     * Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January\n     * 1970.\n     *\n     * @generated from protobuf field: fixed64 start_time_unix_nano = 2;\n     */\n    startTimeUnixNano: number;\n    /**\n     * TimeUnixNano is required, see the detailed comments above Metric.\n     *\n     * Value is UNIX Epoch time in nanoseconds since 00:00:00 UTC on 1 January\n     * 1970.\n     *\n     * @generated from protobuf field: fixed64 time_unix_nano = 3;\n     */\n    timeUnixNano: number;\n    /**\n     * count is the number of values in the population. Must be non-negative.\n     *\n     * @generated from protobuf field: fixed64 count = 4;\n     */\n    count: number;\n    /**\n     * sum of the values in the population. If count is zero then this field\n     * must be zero.\n     *\n     * Note: Sum should only be filled out when measuring non-negative discrete\n     * events, and is assumed to be monotonic over the values of these events.\n     * Negative events *can* be recorded, but sum should not be filled out when\n     * doing so.  This is specifically to enforce compatibility w/ OpenMetrics,\n     * see: https://github.com/OpenObservability/OpenMetrics/blob/main/specification/OpenMetrics.md#summary\n     *\n     * @generated from protobuf field: double sum = 5;\n     */\n    sum: number;\n    /**\n     * (Optional) list of values at different quantiles of the distribution calculated\n     * from the current snapshot. The quantiles must be strictly increasing.\n     *\n     * @generated from protobuf field: repeated opentelemetry.proto.metrics.v1.SummaryDataPoint.ValueAtQuantile quantile_values = 6;\n     */\n    quantileValues: SummaryDataPoint_ValueAtQuantile[];\n    /**\n     * Flags that apply to this specific data point.  See DataPointFlags\n     * for the available flags and their meaning.\n     *\n     * @generated from protobuf field: uint32 flags = 8;\n     */\n    flags: number;\n}\n\n/**\n * @generated MessageType for protobuf message opentelemetry.proto.metrics.v1.SummaryDataPoint\n */\nexport  const SummaryDataPoint: SummaryDataPoint$Type;\n\nexport class SummaryDataPoint_ValueAtQuantile$Type extends MessageType\u003cSummaryDataPoint_ValueAtQuantile\u003e {\n    constructor();\n    create(value?: PartialMessage\u003cSummaryDataPoint_ValueAtQuantile\u003e): SummaryDataPoint_ValueAtQuantile;\n    internalBinaryRead(reader: IBinaryReader, length: number, options: BinaryReadOptions, target?: SummaryDataPoint_ValueAtQuantile): SummaryDataPoint_ValueAtQuantile;\n    internalBinaryWrite(message: SummaryDataPoint_ValueAtQuantile, writer: IBinaryWriter, options: BinaryWriteOptions): IBinaryWriter;\n}\n\n/**\n * Represents the value at a given quantile of a distribution.\n *\n * To record Min and Max values following conventions are used:\n * - The 1.0 quantile is equivalent to the maximum value observed.\n * - The 0.0 quantile is equivalent to the minimum value observed.\n *\n * See the following issue for more context:\n * https://github.com/open-telemetry/opentelemetry-proto/issues/125\n *\n * @generated from protobuf message opentelemetry.proto.metrics.v1.SummaryDataPoint.ValueAtQuantile\n */\nexport  interface SummaryDataPoint_ValueAtQuantile {\n    /**\n     * The quantile of a distribution. Must be in the interval\n     * [0.0, 1.0].\n     *\n     * @generated from protobuf field: double quantile = 1;\n     */\n    quantile: number;\n    /**\n     * The value at the given quantile of a distribution.\n     *\n     * Quantile values must NOT be negative.\n     *\n     * @generated from protobuf field: double value = 2;\n     */\n    value: number;\n}\n\n/**\n * @generated MessageType for protobuf message opentelemetry.proto.metrics.v1.SummaryDataPoint.ValueAtQuantile\n */\nexport  const SummaryDataPoint_ValueAtQuantile: SummaryDataPoint_ValueAtQuantile$Type;\n\nexport class Timestamp$Type extends MessageType\u003cTimestamp\u003e {\n    constructor();\n    /**\n     * Creates a new `Timestamp` for the current time.\n     */\n    now(): Timestamp;\n    /**\n     * Converts a `Timestamp` to a JavaScript Date.\n     */\n    toDate(message: Timestamp): Date;\n    /**\n     * Converts a JavaScript Date to a `Timestamp`.\n     */\n    fromDate(date: Date): Timestamp;\n    /**\n     * In JSON format, the `Timestamp` type is encoded as a string\n     * in the RFC 3339 format.\n     */\n    internalJsonWrite(message: Timestamp, options: JsonWriteOptions): JsonValue;\n    /**\n     * In JSON format, the `Timestamp` type is encoded as a string\n     * in the RFC 3339 format.\n     */\n    internalJsonRead(json: JsonValue, options: JsonReadOptions, target?: Timestamp): Timestamp;\n}\n\n/**\n * A Timestamp represents a point in time independent of any time zone or local\n * calendar, encoded as a count of seconds and fractions of seconds at\n * nanosecond resolution. The count is relative to an epoch at UTC midnight on\n * January 1, 1970, in the proleptic Gregorian calendar which extends the\n * Gregorian calendar backwards to year one.\n *\n * All minutes are 60 seconds long. Leap seconds are \"smeared\" so that no leap\n * second table is needed for interpretation, using a [24-hour linear\n * smear](https://developers.google.com/time/smear).\n *\n * The range is from 0001-01-01T00:00:00Z to 9999-12-31T23:59:59.999999999Z. By\n * restricting to that range, we ensure that we can convert to and from [RFC\n * 3339](https://www.ietf.org/rfc/rfc3339.txt) date strings.\n *\n * # Examples\n *\n * Example 1: Compute Timestamp from POSIX `time()`.\n *\n *     Timestamp timestamp;\n *     timestamp.set_seconds(time(NULL));\n *     timestamp.set_nanos(0);\n *\n * Example 2: Compute Timestamp from POSIX `gettimeofday()`.\n *\n *     struct timeval tv;\n *     gettimeofday(\u0026tv, NULL);\n *\n *     Timestamp timestamp;\n *     timestamp.set_seconds(tv.tv_sec);\n *     timestamp.set_nanos(tv.tv_usec * 1000);\n *\n * Example 3: Compute Timestamp from Win32 `GetSystemTimeAsFileTime()`.\n *\n *     FILETIME ft;\n *     GetSystemTimeAsFileTime(\u0026ft);\n *     UINT64 ticks = (((UINT64)ft.dwHighDateTime) \u003c\u003c 32) | ft.dwLowDateTime;\n *\n *     // A Windows tick is 100 nanoseconds. Windows epoch 1601-01-01T00:00:00Z\n *     // is 11644473600 seconds before Unix epoch 1970-01-01T00:00:00Z.\n *     Timestamp timestamp;\n *     timestamp.set_seconds((INT64) ((ticks / 10000000) - 11644473600LL));\n *     timestamp.set_nanos((INT32) ((ticks % 10000000) * 100));\n *\n * Example 4: Compute Timestamp from Java `System.currentTimeMillis()`.\n *\n *     long millis = System.currentTimeMillis();\n *\n *     Timestamp timestamp = Timestamp.newBuilder().setSeconds(millis / 1000)\n *         .setNanos((int) ((millis % 1000) * 1000000)).build();\n *\n * Example 5: Compute Timestamp from Java `Instant.now()`.\n *\n *     Instant now = Instant.now();\n *\n *     Timestamp timestamp =\n *         Timestamp.newBuilder().setSeconds(now.getEpochSecond())\n *             .setNanos(now.getNano()).build();\n *\n * Example 6: Compute Timestamp from current time in Python.\n *\n *     timestamp = Timestamp()\n *     timestamp.GetCurrentTime()\n *\n * # JSON Mapping\n *\n * In JSON format, the Timestamp type is encoded as a string in the\n * [RFC 3339](https://www.ietf.org/rfc/rfc3339.txt) format. That is, the\n * format is \"{year}-{month}-{day}T{hour}:{min}:{sec}[.{frac_sec}]Z\"\n * where {year} is always expressed using four digits while {month}, {day},\n * {hour}, {min}, and {sec} are zero-padded to two digits each. The fractional\n * seconds, which can go up to 9 digits (i.e. up to 1 nanosecond resolution),\n * are optional. The \"Z\" suffix indicates the timezone (\"UTC\"); the timezone\n * is required. A proto3 JSON serializer should always use UTC (as indicated by\n * \"Z\") when printing the Timestamp type and a proto3 JSON parser should be\n * able to accept both UTC and other timezones (as indicated by an offset).\n *\n * For example, \"2017-01-15T01:30:15.01Z\" encodes 15.01 seconds past\n * 01:30 UTC on January 15, 2017.\n *\n * In JavaScript, one can convert a Date object to this format using the\n * standard\n * [toISOString()](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Date/toISOString)\n * method. In Python, a standard `datetime.datetime` object can be converted\n * to this format using\n * [`strftime`](https://docs.python.org/2/library/time.html#time.strftime) with\n * the time format spec '%Y-%m-%dT%H:%M:%S.%fZ'. Likewise, in Java, one can use\n * the Joda Time's [`ISODateTimeFormat.dateTime()`](\n * http://www.joda.org/joda-time/apidocs/org/joda/time/format/ISODateTimeFormat.html#dateTime%2D%2D\n * ) to obtain a formatter capable of generating timestamps in this format.\n *\n *\n * @generated from protobuf message google.protobuf.Timestamp\n */\nexport  interface Timestamp {\n    /**\n     * Represents seconds of UTC time since Unix epoch\n     * 1970-01-01T00:00:00Z. Must be from 0001-01-01T00:00:00Z to\n     * 9999-12-31T23:59:59Z inclusive.\n     *\n     * @generated from protobuf field: int64 seconds = 1;\n     */\n    seconds: number;\n    /**\n     * Non-negative fractions of a second at nanosecond resolution. Negative\n     * second values with fractions must still have non-negative nanos values\n     * that count forward in time. Must be from 0 to 999,999,999\n     * inclusive.\n     *\n     * @generated from protobuf field: int32 nanos = 2;\n     */\n    nanos: number;\n}\n\n/**\n * @generated MessageType for protobuf message google.protobuf.Timestamp\n */\nexport  const Timestamp: Timestamp$Type;\n\nexport  class Trace extends Config {\n    constructor();\n}\n\nexport class TracesData$Type extends MessageType\u003cTracesData\u003e {\n    constructor();\n    create(value?: PartialMessage\u003cTracesData\u003e): TracesData;\n    internalBinaryRead(reader: IBinaryReader, length: number, options: BinaryReadOptions, target?: TracesData): TracesData;\n    internalBinaryWrite(message: TracesData, writer: IBinaryWriter, options: BinaryWriteOptions): IBinaryWriter;\n}\n\n/**\n * TracesData represents the traces data that can be stored in a persistent storage,\n * OR can be embedded by other protocols that transfer OTLP traces data but do\n * not implement the OTLP protocol.\n *\n * The main difference between this message and collector protocol is that\n * in this message there will not be any \"control\" or \"metadata\" specific to\n * OTLP protocol.\n *\n * When new fields are added into this message, the OTLP request MUST be updated\n * as well.\n *\n * @generated from protobuf message opentelemetry.proto.trace.v1.TracesData\n */\nexport  interface TracesData {\n    /**\n     * An array of ResourceSpans.\n     * For data coming from a single resource this array will typically contain\n     * one element. Intermediary nodes that receive data from multiple origins\n     * typically batch the data before forwarding further and in that case this\n     * array will contain multiple elements.\n     *\n     * @generated from protobuf field: repeated opentelemetry.proto.trace.v1.ResourceSpans resource_spans = 1;\n     */\n    resourceSpans: ResourceSpans[];\n}\n\n/**\n * @generated MessageType for protobuf message opentelemetry.proto.trace.v1.TracesData\n */\nexport  const TracesData: TracesData$Type;\n\n/**\n * A enum field of unknown type.\n */\nexport type UnknownEnum = number;\n\n/**\n * Store an unknown field for a message somewhere.\n */\nexport type UnknownFieldReader = (typeName: string, message: any, fieldNo: number, wireType: WireType, data: Uint8Array) =\u003e void;\n\n/**\n * Write unknown fields stored for the message to the writer.\n */\nexport type UnknownFieldWriter = (typeName: string, message: any, writer: IBinaryWriter) =\u003e void;\n\n/**\n * A map field of unknown type.\n */\nexport type UnknownMap\u003cT = UnknownMessage | UnknownScalar | UnknownEnum\u003e = {\n    [key: string]: T;\n};\n\n/**\n * A message of unknown type.\n */\nexport interface UnknownMessage {\n    [k: string]: UnknownScalar | UnknownEnum | UnknownMessage | UnknownOneofGroup | UnknownMap | UnknownScalar[] | UnknownMessage[] | UnknownEnum[] | undefined;\n}\n\n/**\n * A unknown oneof group. See `isOneofGroup()` for details.\n */\nexport type UnknownOneofGroup = {\n    oneofKind: undefined | string;\n    [k: string]: UnknownScalar | UnknownEnum | UnknownMessage | undefined;\n};\n\n/**\n * A scalar field of unknown type.\n */\nexport type UnknownScalar = string | number | bigint | boolean | Uint8Array;\n\nexport class Value$Type extends MessageType\u003cValue\u003e {\n    constructor();\n    /**\n     * Encode `Value` to JSON value.\n     */\n    internalJsonWrite(message: Value, options: JsonWriteOptions): JsonValue;\n    /**\n     * Decode `Value` from JSON value.\n     */\n    internalJsonRead(json: JsonValue, options: JsonReadOptions, target?: Value): Value;\n}\n\n/**\n * `Value` represents a dynamically typed value which can be either\n * null, a number, a string, a boolean, a recursive struct value, or a\n * list of values. A producer of value is expected to set one of these\n * variants. Absence of any variant indicates an error.\n *\n * The JSON representation for `Value` is JSON value.\n *\n * @generated from protobuf message google.protobuf.Value\n */\nexport interface Value {\n    /**\n     * @generated from protobuf oneof: kind\n     */\n    kind: {\n        oneofKind: \"nullValue\";\n        /**\n         * Represents a null value.\n         *\n         * @generated from protobuf field: google.protobuf.NullValue null_value = 1;\n         */\n        nullValue: NullValue;\n    } | {\n        oneofKind: \"numberValue\";\n        /**\n         * Represents a double value.\n         *\n         * @generated from protobuf field: double number_value = 2;\n         */\n        numberValue: number;\n    } | {\n        oneofKind: \"stringValue\";\n        /**\n         * Represents a string value.\n         *\n         * @generated from protobuf field: string string_value = 3;\n         */\n        stringValue: string;\n    } | {\n        oneofKind: \"boolValue\";\n        /**\n         * Represents a boolean value.\n         *\n         * @generated from protobuf field: bool bool_value = 4;\n         */\n        boolValue: boolean;\n    } | {\n        oneofKind: \"structValue\";\n        /**\n         * Represents a structured value.\n         *\n         * @generated from protobuf field: google.protobuf.Struct struct_value = 5;\n         */\n        structValue: Struct;\n    } | {\n        oneofKind: \"listValue\";\n        /**\n         * Represents a repeated `Value`.\n         *\n         * @generated from protobuf field: google.protobuf.ListValue list_value = 6;\n         */\n        listValue: ListValue;\n    } | {\n        oneofKind: undefined;\n    };\n}\n\n/**\n * @generated MessageType for protobuf message google.protobuf.Value\n */\nexport const Value: Value$Type;\n\n/**\n * Protobuf binary format wire types.\n *\n * A wire type provides just enough information to find the length of the\n * following value.\n *\n * See https://developers.google.com/protocol-buffers/docs/encoding#structure\n */\nexport enum WireType {\n    /**\n     * Used for int32, int64, uint32, uint64, sint32, sint64, bool, enum\n     */\n    Varint = 0,\n    /**\n     * Used for fixed64, sfixed64, double.\n     * Always 8 bytes with little-endian byte order.\n     */\n    Bit64 = 1,\n    /**\n     * Used for string, bytes, embedded messages, packed repeated fields\n     *\n     * Only repeated numeric types (types which use the varint, 32-bit,\n     * or 64-bit wire types) can be packed. In proto3, such fields are\n     * packed by default.\n     */\n    LengthDelimited = 2,\n    /**\n     * Used for groups\n     * @deprecated\n     */\n    StartGroup = 3,\n    /**\n     * Used for groups\n     * @deprecated\n     */\n    EndGroup = 4,\n    /**\n     * Used for fixed32, sfixed32, float.\n     * Always 4 bytes with little-endian byte order.\n     */\n    Bit32 = 5\n}\n\nexport { }\n\n}"}