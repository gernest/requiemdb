package store

import (
	"context"
	"errors"

	"github.com/cespare/xxhash/v2"
	"github.com/dgraph-io/badger/v4"
	"github.com/dgraph-io/ristretto"
	v1 "github.com/gernest/requiemdb/gen/go/rq/v1"
	"github.com/gernest/requiemdb/internal/keys"
	"github.com/gernest/requiemdb/internal/labels"
	"github.com/gernest/requiemdb/internal/lsm"
	"github.com/gernest/requiemdb/internal/transform"
	"github.com/gernest/requiemdb/internal/x"
	"google.golang.org/protobuf/proto"
)

type Storage struct {
	db          *badger.DB
	dataCache   *ristretto.Cache
	bitmapCache *ristretto.Cache
	tree        *lsm.Tree
	seq         *badger.Sequence
}

const (
	DataCacheSize   = 256 << 20
	BitmapCacheSize = DataCacheSize / 2
)

func NewStore(db *badger.DB, tree *lsm.Tree) (*Storage, error) {

	// first 8 is for namespace
	seqKey := make([]byte, 9)
	seqKey[len(seqKey)-1] = byte(v1.RESOURCE_ID)

	seq, err := db.GetSequence(seqKey, 1<<20)
	if err != nil {
		return nil, err
	}
	dataCache, err := ristretto.NewCache(&ristretto.Config{
		NumCounters: 1e7,
		MaxCost:     DataCacheSize,
		BufferItems: 64,
	})
	if err != nil {
		return nil, err
	}
	bitmapCache, err := ristretto.NewCache(&ristretto.Config{
		NumCounters: 1e7,
		MaxCost:     BitmapCacheSize,
		BufferItems: 64,
		OnExit: func(value any) {
			value.(*lsm.Samples).Release()
		},
	})
	if err != nil {
		return nil, err
	}
	return &Storage{
		db:          db,
		dataCache:   dataCache,
		bitmapCache: bitmapCache,
		tree:        tree,
		seq:         seq,
	}, nil
}

func (s *Storage) Close() error {
	s.dataCache.Close()
	s.bitmapCache.Close()
	s.seq.Release()
	return s.tree.Close()
}

func (s *Storage) Start(ctx context.Context) {
	s.tree.Start(ctx)
}

// Save indexes and saves compressed data into badger key/value store. See
// transform package on which metadata is extracted from data for indexing.
//
// Two indexes are kept, all mapping to data. We generate a unique uint64 for
// data which is used to identify data, id is auto increment, giving a sorted
// property of samples.
//
// # Metadata Index
//
// This tracks minTs,maxTs observed in data. For efficiency we use LSM tree
// containing arrow.Record of *v1.Meta. This index is kept in memory and
// persisted for durability but all computation are done in memory using arrow
// compute package.
//
// # Roaring Bitmap Index
//
// This is per label key and kept globally per resource. a single
// roaring64.Bitmap containing all samples that the label was observed is stored
// on the underlying key value store.
//
// Currently , for existing label key we decode the value into a
// *roaring64.Bitmap then we add the sample id and then encode the result before
// updating the key value store with the new value. While memory wise we are
// efficient(we reuse memory to avoid new allocation) this can be adding a lot
// of spikes on cpu so it is probably an area that will benefit further research
// and optimization
//
// Extensive caching is used for keys in this index, we make sure the cache is
// up to date when we observe new labels.
//
// This index is used for performing AND queries where a scan with filters does
// And operation on all matching bitmaps.
func (s *Storage) Save(data *v1.Data) error {
	ctx := transform.NewContext()
	defer ctx.Release()
	ctx.Process(data)
	meta := resourceFrom(data)
	id, err := s.seq.Next()
	if err != nil {
		return err
	}
	txn := s.db.NewTransaction(true)
	defer txn.Discard()

	compressedData, err := x.Compress(proto.Marshal(data))
	if err != nil {
		return err
	}

	key := keys.New()
	defer key.Release()

	sampleKey := key.WithResource(meta).
		WithID(id).
		Encode()

	err = txn.SetEntry(badger.NewEntry(sampleKey, compressedData))
	if err != nil {
		return err
	}

	// Track possible bitmap updates to ensure the cache will have latest bitmaps
	// loaded
	bitmaps := lsm.NewSamples()
	defer bitmaps.Release()

	err = ctx.Labels.Iter(func(lbl *labels.Label) error {
		return saveLabel(txn, lbl.Encode(), id, bitmaps)
	})
	if err != nil {
		return err
	}
	err = txn.Commit()
	if err != nil {
		return err
	}
	// Add sample to index
	s.tree.Append(&v1.Meta{
		Id:       id,
		MinTs:    ctx.MinTs,
		MaxTs:    ctx.MaxTs,
		Resource: uint64(meta),
	})

	// Clear bitmap cache of updated bitmaps
	it := bitmaps.Iterator()
	for it.HasNext() {
		s.bitmapCache.Del(it.Next())
	}
	return nil
}

func resourceFrom(data *v1.Data) v1.RESOURCE {
	switch data.Data.(type) {
	case *v1.Data_Logs:
		return v1.RESOURCE_LOGS
	case *v1.Data_Trace:
		return v1.RESOURCE_TRACES
	default:
		return v1.RESOURCE_METRICS
	}
}

// Saves sampleID in a roaring bitmap for key. key is a serialized label
// generated by transform.Context on a sample.
//
// This is not optimal, for every key we deserialize , add sampleID, and  then
// serialize the bitmap before storing it in txn.
//
// This is acceptable because we only do this per sample.
func saveLabel(txn *badger.Txn, key []byte, sampleID uint64, bitmaps *lsm.Samples) error {
	r := lsm.NewSamples()
	defer r.Release()
	it, err := txn.Get(key)
	if err != nil {
		if !errors.Is(err, badger.ErrKeyNotFound) {
			return err
		}
		r.Add(sampleID)
	} else {
		err = it.Value(r.UnmarshalBinary)
		if err != nil {
			return err
		}
		r.Add(sampleID)
		r.RunOptimize()

		// We only add when doing updates.
		bitmaps.Add(xxhash.Sum64(key))
	}
	data, err := r.MarshalBinary()
	if err != nil {
		return err
	}
	return txn.SetEntry(badger.NewEntry(key, data))
}
